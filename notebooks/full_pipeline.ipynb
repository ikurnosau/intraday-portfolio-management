{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3a6dcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ikurnosau\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime, timezone\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Format for the log messages\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Log to the console\n",
    "    ]\n",
    ")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from data.raw.retrievers.alpaca_markets_retriever import AlpacaMarketsRetriever\n",
    "from config.constants import *\n",
    "from data.processed.dataset_creation import DatasetCreator\n",
    "from data.processed.indicators import *\n",
    "from data.processed.targets import Balanced3ClassClassification\n",
    "from data.processed.normalization import ZScoreOverWindowNormalizer, ZScoreNormalizer, MinMaxNormalizer\n",
    "from data.processed.dataset_pytorch import DatasetPytorch\n",
    "from modeling.trainer import Trainer\n",
    "from modeling.evaluate import evaluate_lgb_regressor, evaluate_torch_regressor, evaluate_torch_regressor_multiasset\n",
    "from observability.mlflow_integration import log_experiment\n",
    "\n",
    "from config.experiments.cur_experiment import config\n",
    "\n",
    "torch.backends.cudnn.benchmark = config.train_config.cudnn_benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "755a729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = AlpacaMarketsRetriever(download_from_gdrive=False)\n",
    "\n",
    "retrieval_result = retriever.bars_with_quotes(\n",
    "    symbol_or_symbols=config.data_config.symbol_or_symbols, \n",
    "    start=config.data_config.start, \n",
    "    end=config.data_config.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d48d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 17:05:29,534 - INFO - Processing AAPL …\n",
      "2025-07-09 17:05:30,186 - INFO - Imputing 496 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:30,795 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:30,830 - INFO - Processing AMD …\n",
      "2025-07-09 17:05:31,494 - INFO - Imputing 214 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:32,100 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:32,130 - INFO - Processing BABA …\n",
      "2025-07-09 17:05:32,767 - INFO - Imputing 874 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:33,349 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:33,380 - INFO - Processing BITU …\n",
      "2025-07-09 17:05:34,029 - INFO - Imputing 6493 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:34,612 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:34,654 - INFO - Processing CSCO …\n",
      "2025-07-09 17:05:35,488 - INFO - Imputing 3929 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:36,074 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:36,110 - INFO - Processing C …\n",
      "2025-07-09 17:05:36,638 - INFO - Imputing 3733 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:37,234 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:37,266 - INFO - Processing DAL …\n",
      "2025-07-09 17:05:37,824 - INFO - Imputing 4112 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:38,423 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:38,450 - INFO - Processing DIA …\n",
      "2025-07-09 17:05:39,066 - INFO - Imputing 3842 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:39,649 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:39,689 - INFO - Processing GLD …\n",
      "2025-07-09 17:05:40,275 - INFO - Imputing 1989 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:40,878 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:40,913 - INFO - Processing GOOG …\n",
      "2025-07-09 17:05:41,586 - INFO - Imputing 1161 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:42,210 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:42,242 - INFO - Processing IJR …\n",
      "2025-07-09 17:05:42,781 - INFO - Imputing 5204 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:43,388 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:43,425 - INFO - Processing MARA …\n",
      "2025-07-09 17:05:44,149 - INFO - Imputing 108 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:44,755 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:44,784 - INFO - Processing MRVL …\n",
      "2025-07-09 17:05:45,360 - INFO - Imputing 2386 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:45,959 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:45,991 - INFO - Processing MU …\n",
      "2025-07-09 17:05:46,639 - INFO - Imputing 838 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:47,280 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:47,312 - INFO - Processing NEE …\n",
      "2025-07-09 17:05:47,911 - INFO - Imputing 4731 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:48,669 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:48,697 - INFO - Processing NKE …\n",
      "2025-07-09 17:05:49,546 - INFO - Imputing 2509 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:50,181 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:50,208 - INFO - Processing NVDA …\n",
      "2025-07-09 17:05:50,931 - INFO - Imputing 1 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:51,496 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:51,523 - INFO - Processing ON …\n",
      "2025-07-09 17:05:52,032 - INFO - Imputing 4325 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:52,583 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:52,608 - INFO - Processing PLTR …\n",
      "2025-07-09 17:05:53,229 - INFO - Imputing 58 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:53,809 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:53,836 - INFO - Processing PYPL …\n",
      "2025-07-09 17:05:54,361 - INFO - Imputing 3097 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:54,927 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:54,954 - INFO - Processing QLD …\n",
      "2025-07-09 17:05:55,486 - INFO - Imputing 4196 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:56,049 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:56,081 - INFO - Processing QQQM …\n",
      "2025-07-09 17:05:56,619 - INFO - Imputing 5090 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:57,194 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:57,233 - INFO - Processing QQQ …\n",
      "2025-07-09 17:05:57,856 - INFO - Imputing 152 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:58,429 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:58,457 - INFO - Processing RKLB …\n",
      "2025-07-09 17:05:59,044 - INFO - Imputing 659 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:05:59,604 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:05:59,629 - INFO - Processing RSP …\n",
      "2025-07-09 17:06:00,183 - INFO - Imputing 4643 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:00,742 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:00,770 - INFO - Processing SMCI …\n",
      "2025-07-09 17:06:01,387 - INFO - Imputing 242 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:01,933 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:01,960 - INFO - Processing SMH …\n",
      "2025-07-09 17:06:02,721 - INFO - Imputing 3394 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:03,287 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:03,312 - INFO - Processing SOXL …\n",
      "2025-07-09 17:06:03,954 - INFO - Imputing 17 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:04,506 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:04,533 - INFO - Processing SOXX …\n",
      "2025-07-09 17:06:05,054 - INFO - Imputing 4248 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:05,631 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:05,658 - INFO - Processing SPXL …\n",
      "2025-07-09 17:06:06,250 - INFO - Imputing 2257 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:06,806 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:06,831 - INFO - Processing SPY …\n",
      "2025-07-09 17:06:07,423 - INFO - Imputing 219 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:08,008 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:08,036 - INFO - Processing TMF …\n",
      "2025-07-09 17:06:08,799 - INFO - Imputing 539 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:09,413 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:09,440 - INFO - Processing TNA …\n",
      "2025-07-09 17:06:10,202 - INFO - Imputing 440 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:10,930 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:10,972 - INFO - Processing TQQQ …\n",
      "2025-07-09 17:06:11,655 - INFO - Imputing 37 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:12,202 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:12,233 - INFO - Processing TSLA …\n",
      "2025-07-09 17:06:12,886 - INFO - Imputing 2 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:13,469 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:13,505 - INFO - Processing UBER …\n",
      "2025-07-09 17:06:14,140 - INFO - Imputing 1667 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:14,760 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:14,790 - INFO - Processing UDOW …\n",
      "2025-07-09 17:06:15,355 - INFO - Imputing 5493 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:15,947 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:15,975 - INFO - Processing UPRO …\n",
      "2025-07-09 17:06:16,827 - INFO - Imputing 1797 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:17,392 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:17,423 - INFO - Processing VOO …\n",
      "2025-07-09 17:06:17,950 - INFO - Imputing 2312 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:18,528 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:18,558 - INFO - Processing WFC …\n",
      "2025-07-09 17:06:19,102 - INFO - Imputing 4302 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:19,729 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:19,759 - INFO - Processing XBI …\n",
      "2025-07-09 17:06:20,270 - INFO - Imputing 4076 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:20,975 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:21,029 - INFO - Processing XLC …\n",
      "2025-07-09 17:06:21,702 - INFO - Imputing 5351 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:22,296 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:22,324 - INFO - Processing XLE …\n",
      "2025-07-09 17:06:22,857 - INFO - Imputing 3826 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:23,444 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:23,474 - INFO - Processing XLI …\n",
      "2025-07-09 17:06:24,062 - INFO - Imputing 5077 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:24,738 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:24,770 - INFO - Processing XLK …\n",
      "2025-07-09 17:06:25,371 - INFO - Imputing 4014 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:25,987 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:26,013 - INFO - Processing XLU …\n",
      "2025-07-09 17:06:26,619 - INFO - Imputing 4835 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:27,259 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:27,303 - INFO - Processing XLV …\n",
      "2025-07-09 17:06:28,029 - INFO - Imputing 4922 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:28,670 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:28,705 - INFO - Processing XLY …\n",
      "2025-07-09 17:06:29,301 - INFO - Imputing 5146 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:29,951 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:29,982 - INFO - Processing XOM …\n",
      "2025-07-09 17:06:30,645 - INFO - Imputing 3570 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:31,261 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:31,290 - INFO - Processing XRT …\n",
      "2025-07-09 17:06:32,128 - INFO - Imputing 5599 NaN rows out of 97359 with forward fill..\n",
      "2025-07-09 17:06:32,746 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-09 17:06:32,778 - INFO - Finished feature generation. 0 assets skipped due to insufficient rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((50, 79969, 60, 15),\n",
       " (50, 79969),\n",
       " (50, 79969),\n",
       " (50, 79969),\n",
       " (50, 7311, 60, 15),\n",
       " (50, 7311),\n",
       " (50, 7311),\n",
       " (50, 7311))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_creator = DatasetCreator(\n",
    "    features=config.data_config.features,\n",
    "    target=config.data_config.target,\n",
    "    normalizer=config.data_config.normalizer,\n",
    "    missing_values_handler=config.data_config.missing_values_handler,\n",
    "    train_set_last_date=config.data_config.train_set_last_date, \n",
    "    in_seq_len=config.data_config.in_seq_len,\n",
    "    multi_asset_prediction=config.data_config.multi_asset_prediction,\n",
    ")\n",
    "\n",
    "X_train, y_train, next_return_train, spread_train, X_test, y_test, next_return_test, spread_test = dataset_creator.create_dataset_numpy(retrieval_result)\n",
    "X_train.shape, y_train.shape, next_return_train.shape, spread_train.shape, X_test.shape, y_test.shape, next_return_test.shape, spread_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f50717e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((79969, 50, 60, 15),\n",
       " (79969, 50),\n",
       " (79969, 50),\n",
       " (79969, 50),\n",
       " (7311, 50, 60, 15),\n",
       " (7311, 50),\n",
       " (7311, 50),\n",
       " (7311, 50))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if config.data_config.multi_asset_prediction:\n",
    "    X_train = np.swapaxes(X_train, 0, 1)\n",
    "    y_train = np.swapaxes(y_train, 0, 1)\n",
    "    next_return_train = np.swapaxes(next_return_train, 0, 1)\n",
    "    spread_train = np.swapaxes(spread_train, 0, 1)\n",
    "\n",
    "    X_test = np.swapaxes(X_test, 0, 1)\n",
    "    y_test = np.swapaxes(y_test, 0, 1)\n",
    "    next_return_test = np.swapaxes(next_return_test, 0, 1)\n",
    "    spread_test = np.swapaxes(spread_test, 0, 1)\n",
    "\n",
    "X_train.shape, y_train.shape, next_return_train.shape, spread_train.shape, X_test.shape, y_test.shape, next_return_test.shape, spread_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc91696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49992302, 0.501705)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b98a4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DatasetPytorch(X_train, y_train, learning_task='regression').as_dataloader(\n",
    "    batch_size=config.train_config.batch_size,\n",
    "    shuffle=config.train_config.shuffle,\n",
    "    num_workers=config.train_config.num_workers,\n",
    "    prefetch_factor=config.train_config.prefetch_factor,\n",
    "    pin_memory=config.train_config.pin_memory,\n",
    "    persistent_workers=config.train_config.persistent_workers,\n",
    "    drop_last=config.train_config.drop_last\n",
    ")\n",
    "test_loader = DatasetPytorch(X_test, y_test, learning_task='regression').as_dataloader(\n",
    "    batch_size=config.train_config.batch_size,\n",
    "    shuffle=config.train_config.shuffle,\n",
    "    num_workers=config.train_config.num_workers,\n",
    "    prefetch_factor=config.train_config.prefetch_factor,\n",
    "    pin_memory=config.train_config.pin_memory,\n",
    "    persistent_workers=config.train_config.persistent_workers,\n",
    "    drop_last=config.train_config.drop_last\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c4b5aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemporalSpatial(\n",
       "  (asset_embed): Embedding(50, 16)\n",
       "  (asset_proj): Linear(in_features=16, out_features=128, bias=False)\n",
       "  (lstm): LSTM(15, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (spatial_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = config.model_config.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a3858fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    loss_fn=config.train_config.loss_fn,\n",
    "    optimizer=config.train_config.optimizer,\n",
    "    scheduler=config.train_config.scheduler,\n",
    "    num_epochs=config.train_config.num_epochs,\n",
    "    device=config.train_config.device,\n",
    "    metrics=config.train_config.metrics,\n",
    "    save_path=config.train_config.save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f01c52e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 17:07:30,201 - INFO - Epoch 1/1\n",
      "2025-07-09 17:09:57,491 - INFO - Train Loss: 0.1426         \n",
      "2025-07-09 17:09:57,502 - INFO - Train Rmse: 0.3757\n",
      "2025-07-09 17:09:57,503 - INFO - Val   Loss: 0.1167\n",
      "2025-07-09 17:09:57,506 - INFO - Val   Rmse: 0.3416\n",
      "2025-07-09 17:09:57,510 - INFO - \n"
     ]
    }
   ],
   "source": [
    "model, history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3802d5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 22.62 GiB. GPU 0 has a total capacity of 8.00 GiB of which 1.71 GiB is free. Of the allocated memory 2.64 GiB is allocated by PyTorch, and 2.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevaluate_torch_regressor_multiasset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_return_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspread_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\Projects\\QuantitativeTrading\\intraday-portfolio-management\\modeling\\evaluate.py:146\u001b[0m, in \u001b[0;36mevaluate_torch_regressor_multiasset\u001b[1;34m(model, X_train, y_train, X_test, y_test, test_return, test_spread, trade_asset_count)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Run batched predictions\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m train_preds_arr \u001b[38;5;241m=\u001b[39m \u001b[43m_predict_in_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m test_preds_arr \u001b[38;5;241m=\u001b[39m _predict_in_batches(X_test)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Select the *trade_asset_count* most confident assets per time step\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\Projects\\QuantitativeTrading\\intraday-portfolio-management\\modeling\\evaluate.py:136\u001b[0m, in \u001b[0;36mevaluate_torch_regressor_multiasset.<locals>._predict_in_batches\u001b[1;34m(X, batch_size)\u001b[0m\n\u001b[0;32m    134\u001b[0m batch \u001b[38;5;241m=\u001b[39m X[i : i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m    135\u001b[0m batch_t \u001b[38;5;241m=\u001b[39m _to_tensor(batch, device, torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m--> 136\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# squeeze regression singleton dim if present\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\Projects\\QuantitativeTrading\\intraday-portfolio-management\\modeling\\models\\tsa_classifier.py:78\u001b[0m, in \u001b[0;36mTemporalSpatial.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# (B*A, T, F) → LSTM → (B*A, H)\u001b[39;00m\n\u001b[0;32m     77\u001b[0m x_flat \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(B \u001b[38;5;241m*\u001b[39m A, T, F)\n\u001b[1;32m---> 78\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m h \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# last time step (B*A, H)\u001b[39;00m\n\u001b[0;32m     80\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(h)\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1123\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1137\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1145\u001b[0m     )\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 22.62 GiB. GPU 0 has a total capacity of 8.00 GiB of which 1.71 GiB is free. Of the allocated memory 2.64 GiB is allocated by PyTorch, and 2.48 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "evaluate_torch_regressor_multiasset(model, X_train, y_train, X_test, y_test, next_return_test, spread_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed829636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 15:35:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'LSTM Default' already exists. Creating a new version of this model...\n",
      "2025/06/26 15:35:14 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LSTM Default, version 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run gentle-loon-699 at: http://127.0.0.1:8080/#/experiments/439216085822475480/runs/54deb1104660468d9ffb4e7e278e9cfb\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/439216085822475480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '10' of model 'LSTM Default'.\n"
     ]
    }
   ],
   "source": [
    "log_experiment(\n",
    "    config=config, \n",
    "    model=model, \n",
    "    history=history,\n",
    "    input_data_sample=next(iter(train_loader))[0].to(trainer.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c286205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9435\n",
      "[LightGBM] [Info] Number of data points in the train set: 7371, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 0.497863\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Train rmse: 0.26411260601695974, Test rmse: 0.2684210886033184, Baseline rmse: 0.2599985897541046\n",
      "Expected return: 0.00010183148393891163, Baseline return: 2.569958041931386e-06, Max possible return 0.00048079571570269763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "evaluate_lgb_regressor(X_train, y_train, X_test, y_test, next_return_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
