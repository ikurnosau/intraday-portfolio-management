{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3a6dcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime, timezone\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Format for the log messages\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Log to the console\n",
    "    ]\n",
    ")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from data.raw.retrievers.alpaca_markets_retriever import AlpacaMarketsRetriever\n",
    "from config.constants import *\n",
    "from data.processed.dataset_creation import DatasetCreator\n",
    "from data.processed.indicators import *\n",
    "from data.processed.targets import Balanced3ClassClassification\n",
    "from data.processed.normalization import ZScoreOverWindowNormalizer, ZScoreNormalizer, MinMaxNormalizer\n",
    "from data.processed.dataset_pytorch import DatasetPytorch\n",
    "from modeling.trainer import Trainer\n",
    "from modeling.evaluate import evaluate_lgb_regressor, evaluate_torch_regressor, evaluate_torch_regressor_multiasset\n",
    "# from observability.mlflow_integration import log_experiment\n",
    "\n",
    "from modeling.rl.environment import PortfolioEnvironment\n",
    "from modeling.rl.state import State\n",
    "from modeling.rl.agent import RlAgent\n",
    "from modeling.rl.algorithms.policy_gradient import PolicyGradient\n",
    "from modeling.rl.actors.actor import RlActor, FullyConnectedBackend, TransformerBackend\n",
    "from modeling.rl.actors.signal_predictor_actor import SignalPredictorActor\n",
    "from modeling.rl.actors.high_energy_low_friction_actor import HighEnergyLowFrictionActor\n",
    "from modeling.rl.actors.xsmom_actor import XSMomActor\n",
    "from modeling.rl.actors.tsmom_actor import TSMomActor\n",
    "from modeling.rl.actors.blsw_actor import BLSWActor\n",
    "from modeling.rl.trajectory_dataset import TrajectoryDataset\n",
    "from modeling.rl.metrics import MetricsCalculator, DEFAULT_METRICS\n",
    "from modeling.rl.reward import EstimatedReturnReward\n",
    "from modeling.rl.loss import SumLogReturnLoss\n",
    "from modeling.rl.visualization.wealth_plot import plot_cumulative_wealth\n",
    "from modeling.rl.visualization.position_plot import plot_position_heatmap\n",
    "from config.experiments.cur_experiment import config\n",
    "\n",
    "torch.backends.cudnn.benchmark = config.train_config.cudnn_benchmark\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "755a729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1oE69lvgomUzIqJHCOJ4N1g6opWuv1coW\n",
      "From (redirected): https://drive.google.com/uc?id=1oE69lvgomUzIqJHCOJ4N1g6opWuv1coW&confirm=t&uuid=e0188477-d002-4a6b-af33-bd71e868eb89\n",
      "To: /workspace/intraday-portfolio-management/data/raw/alpaca/bars_with_quotes/1Min_2024-06-01-2025-06-01_AAPL+AMD+BABA+BITU+C+CSCO+DAL+DIA+GLD+GOOG+IJR+MARA+MRVL+MU+NEE+NKE+NVDA+ON+PLTR+PYPL+QLD+QQQ+QQQM+R.pkl\n",
      "100%|██████████| 587M/587M [00:03<00:00, 167MB/s]  \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1fBIwQMGOf-cV5IN-psvWqSV2I3MvPum_\n",
      "To: /workspace/intraday-portfolio-management/modeling/checkpoints/best_model.pth\n",
      "100%|██████████| 25.4M/25.4M [00:00<00:00, 103MB/s] \n"
     ]
    }
   ],
   "source": [
    "retriever = AlpacaMarketsRetriever(download_from_gdrive=True)\n",
    "\n",
    "retrieval_result = retriever.bars_with_quotes(\n",
    "    symbol_or_symbols=config.data_config.symbol_or_symbols,\n",
    "    start=config.data_config.start,\n",
    "    end=config.data_config.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d48d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 16:14:09,565 - INFO - Processing AAPL …\n",
      "2025-08-11 16:14:09,820 - INFO - Imputing 496 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:10,046 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:10,095 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:10,103 - INFO - Processing AMD …\n",
      "2025-08-11 16:14:10,325 - INFO - Imputing 214 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:10,536 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:10,584 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:10,592 - INFO - Processing BABA …\n",
      "2025-08-11 16:14:10,920 - INFO - Imputing 874 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:11,132 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:11,180 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:11,188 - INFO - Processing BITU …\n",
      "2025-08-11 16:14:11,387 - INFO - Imputing 6493 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:11,602 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:11,649 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:11,657 - INFO - Processing CSCO …\n",
      "2025-08-11 16:14:11,833 - INFO - Imputing 3929 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:12,043 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:12,091 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:12,101 - INFO - Processing C …\n",
      "2025-08-11 16:14:12,276 - INFO - Imputing 3733 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:12,486 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:12,534 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:12,542 - INFO - Processing DAL …\n",
      "2025-08-11 16:14:12,811 - INFO - Imputing 4112 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:13,022 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:13,072 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:13,080 - INFO - Processing DIA …\n",
      "2025-08-11 16:14:13,270 - INFO - Imputing 3842 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:13,489 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:13,538 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:13,548 - INFO - Processing GLD …\n",
      "2025-08-11 16:14:13,746 - INFO - Imputing 1989 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:13,968 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:14,017 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:14,027 - INFO - Processing GOOG …\n",
      "2025-08-11 16:14:14,232 - INFO - Imputing 1161 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:14,454 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:14,502 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:14,510 - INFO - Processing IJR …\n",
      "2025-08-11 16:14:14,682 - INFO - Imputing 5204 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:15,028 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:15,076 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:15,086 - INFO - Processing MARA …\n",
      "2025-08-11 16:14:15,311 - INFO - Imputing 108 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:15,529 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:15,582 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:15,591 - INFO - Processing MRVL …\n",
      "2025-08-11 16:14:15,782 - INFO - Imputing 2386 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:15,998 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:16,051 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:16,061 - INFO - Processing MU …\n",
      "2025-08-11 16:14:16,269 - INFO - Imputing 838 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:16,486 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:16,539 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:16,548 - INFO - Processing NEE …\n",
      "2025-08-11 16:14:16,722 - INFO - Imputing 4731 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:17,067 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:17,116 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:17,126 - INFO - Processing NKE …\n",
      "2025-08-11 16:14:17,317 - INFO - Imputing 2509 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:17,532 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:17,580 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:17,588 - INFO - Processing NVDA …\n",
      "2025-08-11 16:14:17,828 - INFO - Imputing 1 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:18,047 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:18,095 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:18,104 - INFO - Processing ON …\n",
      "2025-08-11 16:14:18,284 - INFO - Imputing 4325 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:18,504 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:18,552 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:18,560 - INFO - Processing PLTR …\n",
      "2025-08-11 16:14:18,910 - INFO - Imputing 58 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:19,134 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:19,182 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:19,190 - INFO - Processing PYPL …\n",
      "2025-08-11 16:14:19,379 - INFO - Imputing 3097 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:19,597 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:19,646 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:19,655 - INFO - Processing QLD …\n",
      "2025-08-11 16:14:19,854 - INFO - Imputing 4196 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:20,068 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:20,117 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:20,125 - INFO - Processing QQQM …\n",
      "2025-08-11 16:14:20,309 - INFO - Imputing 5090 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:20,638 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:20,689 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:20,697 - INFO - Processing QQQ …\n",
      "2025-08-11 16:14:20,927 - INFO - Imputing 152 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:21,148 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:21,196 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:21,204 - INFO - Processing RKLB …\n",
      "2025-08-11 16:14:21,414 - INFO - Imputing 659 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:21,634 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:21,682 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:21,690 - INFO - Processing RSP …\n",
      "2025-08-11 16:14:21,865 - INFO - Imputing 4643 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:22,086 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:22,135 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:22,143 - INFO - Processing SMCI …\n",
      "2025-08-11 16:14:22,359 - INFO - Imputing 242 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:22,585 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:22,633 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:22,642 - INFO - Processing SMH …\n",
      "2025-08-11 16:14:22,970 - INFO - Imputing 3394 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:23,189 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:23,237 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:23,245 - INFO - Processing SOXL …\n",
      "2025-08-11 16:14:23,484 - INFO - Imputing 17 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:23,707 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:23,755 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:23,764 - INFO - Processing SOXX …\n",
      "2025-08-11 16:14:23,949 - INFO - Imputing 4248 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:24,167 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:24,216 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:24,224 - INFO - Processing SPXL …\n",
      "2025-08-11 16:14:24,430 - INFO - Imputing 2257 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:24,770 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:24,819 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:24,828 - INFO - Processing SPY …\n",
      "2025-08-11 16:14:25,050 - INFO - Imputing 219 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:25,268 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:25,316 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:25,324 - INFO - Processing TMF …\n",
      "2025-08-11 16:14:25,543 - INFO - Imputing 539 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:25,764 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:25,812 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:25,820 - INFO - Processing TNA …\n",
      "2025-08-11 16:14:26,038 - INFO - Imputing 440 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:26,259 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:26,307 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:26,316 - INFO - Processing TQQQ …\n",
      "2025-08-11 16:14:26,550 - INFO - Imputing 37 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:26,767 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:26,815 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:26,823 - INFO - Processing TSLA …\n",
      "2025-08-11 16:14:27,186 - INFO - Imputing 2 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:27,402 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:27,450 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:27,458 - INFO - Processing UBER …\n",
      "2025-08-11 16:14:27,650 - INFO - Imputing 1667 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:27,865 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:27,913 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:27,921 - INFO - Processing UDOW …\n",
      "2025-08-11 16:14:28,111 - INFO - Imputing 5493 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:28,325 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:28,373 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:28,382 - INFO - Processing UPRO …\n",
      "2025-08-11 16:14:28,588 - INFO - Imputing 1797 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:28,914 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:28,962 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:28,971 - INFO - Processing VOO …\n",
      "2025-08-11 16:14:29,161 - INFO - Imputing 2312 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:29,374 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:29,422 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:29,430 - INFO - Processing WFC …\n",
      "2025-08-11 16:14:29,611 - INFO - Imputing 4302 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:29,831 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:29,881 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:29,890 - INFO - Processing XBI …\n",
      "2025-08-11 16:14:30,072 - INFO - Imputing 4076 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:30,285 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:30,333 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:30,342 - INFO - Processing XLC …\n",
      "2025-08-11 16:14:30,621 - INFO - Imputing 5351 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:30,834 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:30,882 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:30,891 - INFO - Processing XLE …\n",
      "2025-08-11 16:14:31,071 - INFO - Imputing 3826 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:31,286 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:31,334 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:31,342 - INFO - Processing XLI …\n",
      "2025-08-11 16:14:31,515 - INFO - Imputing 5077 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:31,732 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:31,780 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:31,789 - INFO - Processing XLK …\n",
      "2025-08-11 16:14:31,969 - INFO - Imputing 4014 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:32,182 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:32,231 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:32,239 - INFO - Processing XLU …\n",
      "2025-08-11 16:14:32,541 - INFO - Imputing 4835 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:32,755 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:32,804 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:32,812 - INFO - Processing XLV …\n",
      "2025-08-11 16:14:32,990 - INFO - Imputing 4922 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:33,204 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:33,252 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:33,261 - INFO - Processing XLY …\n",
      "2025-08-11 16:14:33,436 - INFO - Imputing 5146 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:33,648 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:33,696 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:33,705 - INFO - Processing XOM …\n",
      "2025-08-11 16:14:33,889 - INFO - Imputing 3570 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:34,102 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:34,150 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:34,158 - INFO - Processing XRT …\n",
      "2025-08-11 16:14:34,336 - INFO - Imputing 5599 NaN rows out of 97359 with forward fill..\n",
      "2025-08-11 16:14:34,670 - INFO - Spread has 0 NaNs\n",
      "2025-08-11 16:14:34,718 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-08-11 16:14:34,727 - INFO - Finished feature generation. 0 assets skipped due to insufficient rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((79741, 50, 60, 15),\n",
       " (79741, 50),\n",
       " (79741, 50),\n",
       " (79741, 50),\n",
       " (79741, 50),\n",
       " (7291, 50, 60, 15),\n",
       " (7291, 50),\n",
       " (7291, 50),\n",
       " (7291, 50),\n",
       " (7291, 50))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_creator = DatasetCreator(\n",
    "    features=config.data_config.features,\n",
    "    target=config.data_config.target,\n",
    "    normalizer=config.data_config.normalizer,\n",
    "    missing_values_handler=config.data_config.missing_values_handler,\n",
    "    train_set_last_date=config.data_config.train_set_last_date, \n",
    "    in_seq_len=config.data_config.in_seq_len,\n",
    "    multi_asset_prediction=config.data_config.multi_asset_prediction,\n",
    ")\n",
    "\n",
    "X_train, y_train, next_return_train, spread_train, volatility_train, X_test, y_test, next_return_test, spread_test, volatility_test = dataset_creator.create_dataset_numpy(retrieval_result)\n",
    "X_train.shape, y_train.shape, next_return_train.shape, spread_train.shape, volatility_train.shape, X_test.shape, y_test.shape, next_return_test.shape, spread_test.shape, volatility_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d115f18-b628-43a2-bdee-01dd74f6bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test, y_test, next_return_test, spread_test, volatility_test = X_test[:7000], y_test[:7000], next_return_test[:7000], spread_test[:7000], volatility_test[:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc91696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49983266, 0.50164175)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b98a4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DatasetPytorch(X_train, y_train, learning_task='regression').as_dataloader(\n",
    "    batch_size=config.train_config.batch_size,\n",
    "    shuffle=config.train_config.shuffle,\n",
    "    num_workers=config.train_config.num_workers,\n",
    "    prefetch_factor=config.train_config.prefetch_factor,\n",
    "    pin_memory=config.train_config.pin_memory,\n",
    "    persistent_workers=config.train_config.persistent_workers,\n",
    "    drop_last=config.train_config.drop_last\n",
    ")\n",
    "test_loader = DatasetPytorch(X_test, y_test, learning_task='regression').as_dataloader(\n",
    "    batch_size=config.train_config.batch_size,\n",
    "    shuffle=config.train_config.shuffle,\n",
    "    num_workers=config.train_config.num_workers,\n",
    "    prefetch_factor=config.train_config.prefetch_factor,\n",
    "    pin_memory=config.train_config.pin_memory,\n",
    "    persistent_workers=config.train_config.persistent_workers,\n",
    "    drop_last=config.train_config.drop_last\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c4b5aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemporalSpatial(\n",
       "  (asset_embed): Embedding(50, 16)\n",
       "  (asset_proj): Linear(in_features=16, out_features=256, bias=False)\n",
       "  (lstm): LSTM(15, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (spatial_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = config.model_config.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa26ca6-8128-4e85-be01-34335ab51675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExperimentConfig(data_config=DataConfig(symbol_or_symbols=['AAPL', 'AMD', 'BABA', 'BITU', 'C', 'CSCO', 'DAL', 'DIA', 'GLD', 'GOOG', 'IJR', 'MARA', 'MRVL', 'MU', 'NEE', 'NKE', 'NVDA', 'ON', 'PLTR', 'PYPL', 'QLD', 'QQQ', 'QQQM', 'RKLB', 'RSP', 'SMCI', 'SMH', 'SOXL', 'SOXX', 'SPXL', 'SPY', 'TMF', 'TNA', 'TQQQ', 'TSLA', 'UBER', 'UDOW', 'UPRO', 'VOO', 'WFC', 'XBI', 'XLC', 'XLE', 'XLI', 'XLK', 'XLU', 'XLV', 'XLY', 'XOM', 'XRT'], start=datetime.datetime(2024, 6, 1, 0, 0), end=datetime.datetime(2025, 6, 1, 0, 0), features={'log_ret': <function <lambda> at 0x7f96b70f6ca0>, 'hl_range': <function <lambda> at 0x7f96b70f6de0>, 'close_open': <function <lambda> at 0x7f96b6f08a40>, 'vol_delta': <function <lambda> at 0x7f96b6f08ae0>, 'EMA_fast': <data.processed.indicators.EMA object at 0x7f96b70bda90>, 'EMA_slow': <data.processed.indicators.EMA object at 0x7f96b709cb90>, 'RSI2': <data.processed.indicators.RSI object at 0x7f96b704ff50>, 'RSI6': <data.processed.indicators.RSI object at 0x7f96c720af90>, 'realvol20': <function <lambda> at 0x7f96b6f08b80>, 'VWAP_dist': <function <lambda> at 0x7f96b6f08c20>, 'loc_in_range': <function <lambda> at 0x7f96b6f08cc0>, 'tod_sin': <function <lambda> at 0x7f96b6f08d60>, 'tod_cos': <function <lambda> at 0x7f96b6f08e00>, 'ema_slope': <function <lambda> at 0x7f96b6f08ea0>, 'vol_slope': <function <lambda> at 0x7f96b6f08f40>}, target=<data.processed.targets.FutureMeanReturnClassification object at 0x7f96b70f2d50>, normalizer=<data.processed.normalization.MinMaxNormalizerOverWindow object at 0x7f96b70d5450>, missing_values_handler=<data.processed.missing_values_handling.ForwardFillFlatBars object at 0x7f96be58cb10>, in_seq_len=60, train_set_last_date=datetime.datetime(2025, 5, 1, 0, 0, tzinfo=datetime.timezone.utc), multi_asset_prediction=True, cutoff_time=datetime.time(14, 10)), model_config=ModelConfig(model=TemporalSpatial(\n",
       "  (asset_embed): Embedding(50, 16)\n",
       "  (asset_proj): Linear(in_features=16, out_features=256, bias=False)\n",
       "  (lstm): LSTM(15, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (spatial_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "), registered_model_name='TemporalSpatial Regressor'), train_config=TrainConfig(loss_fn=MSELoss(), optimizer=AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: True\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    decoupled_weight_decay: True\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 1e-10\n",
       "), scheduler={'type': 'OneCycleLR', 'max_lr': 0.003, 'pct_start': 0.1, 'div_factor': 25, 'final_div_factor': 1000.0, 'anneal_strategy': 'cos', 'cycle_momentum': False}, num_epochs=20, early_stopping_patience=5, device=device(type='cuda'), cudnn_benchmark=True, metrics={'rmse': <function rmse_regression at 0x7f96b6f080e0>}, batch_size=128, shuffle=True, num_workers=8, prefetch_factor=4, pin_memory=True, persistent_workers=True, drop_last=True, save_path=''), observability_config=ObservabilityConfig(experiment_name='Return Regression MLP'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a3858fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    loss_fn=config.train_config.loss_fn,\n",
    "    optimizer=config.train_config.optimizer,\n",
    "    scheduler=config.train_config.scheduler,\n",
    "    num_epochs=config.train_config.num_epochs,\n",
    "    device=config.train_config.device,\n",
    "    metrics=config.train_config.metrics,\n",
    "    save_path=config.train_config.save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1da6d315-3bf8-452a-ba17-6badd562dd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1021\n",
    "# 0.3199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f01c52e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 16:14:37,973 - INFO - Epoch 1/20\n",
      "2025-08-11 16:15:24,477 - INFO - Train Loss: 0.1358        \n",
      "2025-08-11 16:15:24,477 - INFO - Train Rmse: 0.3670\n",
      "2025-08-11 16:15:24,477 - INFO - Val   Loss: 0.1219\n",
      "2025-08-11 16:15:24,477 - INFO - Val   Rmse: 0.3490\n",
      "2025-08-11 16:15:24,477 - INFO - \n",
      "2025-08-11 16:15:24,479 - INFO - Epoch 2/20\n",
      "2025-08-11 16:16:05,813 - INFO - Train Loss: 0.1253        \n",
      "2025-08-11 16:16:05,814 - INFO - Train Rmse: 0.3539\n",
      "2025-08-11 16:16:05,814 - INFO - Val   Loss: 0.1171\n",
      "2025-08-11 16:16:05,814 - INFO - Val   Rmse: 0.3421\n",
      "2025-08-11 16:16:05,815 - INFO - \n",
      "2025-08-11 16:16:05,816 - INFO - Epoch 3/20\n",
      "2025-08-11 16:16:47,121 - INFO - Train Loss: 0.1240        \n",
      "2025-08-11 16:16:47,121 - INFO - Train Rmse: 0.3521\n",
      "2025-08-11 16:16:47,122 - INFO - Val   Loss: 0.1160\n",
      "2025-08-11 16:16:47,122 - INFO - Val   Rmse: 0.3405\n",
      "2025-08-11 16:16:47,122 - INFO - \n",
      "2025-08-11 16:16:47,123 - INFO - Epoch 4/20\n",
      "2025-08-11 16:17:28,418 - INFO - Train Loss: 0.1235        \n",
      "2025-08-11 16:17:28,419 - INFO - Train Rmse: 0.3514\n",
      "2025-08-11 16:17:28,419 - INFO - Val   Loss: 0.1161\n",
      "2025-08-11 16:17:28,419 - INFO - Val   Rmse: 0.3408\n",
      "2025-08-11 16:17:28,419 - INFO - \n",
      "2025-08-11 16:17:28,419 - INFO - Epoch 5/20\n",
      "2025-08-11 16:18:09,781 - INFO - Train Loss: 0.1231        \n",
      "2025-08-11 16:18:09,782 - INFO - Train Rmse: 0.3507\n",
      "2025-08-11 16:18:09,782 - INFO - Val   Loss: 0.1160\n",
      "2025-08-11 16:18:09,782 - INFO - Val   Rmse: 0.3406\n",
      "2025-08-11 16:18:09,782 - INFO - \n",
      "2025-08-11 16:18:09,782 - INFO - Epoch 6/20\n",
      "2025-08-11 16:18:51,146 - INFO - Train Loss: 0.1228        \n",
      "2025-08-11 16:18:51,146 - INFO - Train Rmse: 0.3504\n",
      "2025-08-11 16:18:51,146 - INFO - Val   Loss: 0.1157\n",
      "2025-08-11 16:18:51,146 - INFO - Val   Rmse: 0.3402\n",
      "2025-08-11 16:18:51,146 - INFO - \n",
      "2025-08-11 16:18:51,148 - INFO - Epoch 7/20\n",
      "2025-08-11 16:19:32,458 - INFO - Train Loss: 0.1226        \n",
      "2025-08-11 16:19:32,459 - INFO - Train Rmse: 0.3501\n",
      "2025-08-11 16:19:32,459 - INFO - Val   Loss: 0.1158\n",
      "2025-08-11 16:19:32,459 - INFO - Val   Rmse: 0.3402\n",
      "2025-08-11 16:19:32,459 - INFO - \n",
      "2025-08-11 16:19:32,459 - INFO - Epoch 8/20\n",
      "2025-08-11 16:20:13,769 - INFO - Train Loss: 0.1225        \n",
      "2025-08-11 16:20:13,770 - INFO - Train Rmse: 0.3500\n",
      "2025-08-11 16:20:13,770 - INFO - Val   Loss: 0.1156\n",
      "2025-08-11 16:20:13,770 - INFO - Val   Rmse: 0.3400\n",
      "2025-08-11 16:20:13,770 - INFO - \n",
      "2025-08-11 16:20:13,772 - INFO - Epoch 9/20\n",
      "2025-08-11 16:20:55,099 - INFO - Train Loss: 0.1225        \n",
      "2025-08-11 16:20:55,100 - INFO - Train Rmse: 0.3499\n",
      "2025-08-11 16:20:55,100 - INFO - Val   Loss: 0.1157\n",
      "2025-08-11 16:20:55,100 - INFO - Val   Rmse: 0.3401\n",
      "2025-08-11 16:20:55,100 - INFO - \n",
      "2025-08-11 16:20:55,100 - INFO - Epoch 10/20\n",
      "2025-08-11 16:21:36,464 - INFO - Train Loss: 0.1224        \n",
      "2025-08-11 16:21:36,464 - INFO - Train Rmse: 0.3498\n",
      "2025-08-11 16:21:36,464 - INFO - Val   Loss: 0.1156\n",
      "2025-08-11 16:21:36,465 - INFO - Val   Rmse: 0.3400\n",
      "2025-08-11 16:21:36,465 - INFO - \n",
      "2025-08-11 16:21:36,466 - INFO - Epoch 11/20\n",
      "2025-08-11 16:22:17,815 - INFO - Train Loss: 0.1224        \n",
      "2025-08-11 16:22:17,816 - INFO - Train Rmse: 0.3497\n",
      "2025-08-11 16:22:17,816 - INFO - Val   Loss: 0.1157\n",
      "2025-08-11 16:22:17,816 - INFO - Val   Rmse: 0.3400\n",
      "2025-08-11 16:22:17,816 - INFO - \n",
      "2025-08-11 16:22:17,816 - INFO - Epoch 12/20\n",
      "2025-08-11 16:22:59,138 - INFO - Train Loss: 0.1223        \n",
      "2025-08-11 16:22:59,139 - INFO - Train Rmse: 0.3496\n",
      "2025-08-11 16:22:59,139 - INFO - Val   Loss: 0.1154\n",
      "2025-08-11 16:22:59,139 - INFO - Val   Rmse: 0.3397\n",
      "2025-08-11 16:22:59,139 - INFO - \n",
      "2025-08-11 16:22:59,141 - INFO - Epoch 13/20\n",
      "2025-08-11 16:23:40,530 - INFO - Train Loss: 0.1222        \n",
      "2025-08-11 16:23:40,531 - INFO - Train Rmse: 0.3496\n",
      "2025-08-11 16:23:40,531 - INFO - Val   Loss: 0.1156\n",
      "2025-08-11 16:23:40,531 - INFO - Val   Rmse: 0.3399\n",
      "2025-08-11 16:23:40,531 - INFO - \n",
      "2025-08-11 16:23:40,531 - INFO - Epoch 14/20\n",
      "2025-08-11 16:24:21,861 - INFO - Train Loss: 0.1222        \n",
      "2025-08-11 16:24:21,862 - INFO - Train Rmse: 0.3495\n",
      "2025-08-11 16:24:21,862 - INFO - Val   Loss: 0.1155\n",
      "2025-08-11 16:24:21,862 - INFO - Val   Rmse: 0.3398\n",
      "2025-08-11 16:24:21,862 - INFO - \n",
      "2025-08-11 16:24:21,862 - INFO - Epoch 15/20\n",
      "2025-08-11 16:25:03,188 - INFO - Train Loss: 0.1222        \n",
      "2025-08-11 16:25:03,189 - INFO - Train Rmse: 0.3495\n",
      "2025-08-11 16:25:03,189 - INFO - Val   Loss: 0.1156\n",
      "2025-08-11 16:25:03,190 - INFO - Val   Rmse: 0.3399\n",
      "2025-08-11 16:25:03,190 - INFO - \n",
      "2025-08-11 16:25:03,190 - INFO - Epoch 16/20\n",
      "2025-08-11 16:25:44,498 - INFO - Train Loss: 0.1221        \n",
      "2025-08-11 16:25:44,498 - INFO - Train Rmse: 0.3494\n",
      "2025-08-11 16:25:44,498 - INFO - Val   Loss: 0.1154\n",
      "2025-08-11 16:25:44,498 - INFO - Val   Rmse: 0.3397\n",
      "2025-08-11 16:25:44,499 - INFO - \n",
      "2025-08-11 16:25:44,499 - INFO - Epoch 17/20\n",
      "2025-08-11 16:26:25,791 - INFO - Train Loss: 0.1221        \n",
      "2025-08-11 16:26:25,791 - INFO - Train Rmse: 0.3494\n",
      "2025-08-11 16:26:25,792 - INFO - Val   Loss: 0.1155\n",
      "2025-08-11 16:26:25,792 - INFO - Val   Rmse: 0.3398\n",
      "2025-08-11 16:26:25,792 - INFO - \n",
      "2025-08-11 16:26:25,792 - INFO - Early stopping triggered at epoch 17\n"
     ]
    }
   ],
   "source": [
    "model, history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ee085a5-1251-4816-84f2-f591c882b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trajectory_loader = TrajectoryDataset(X_train, next_return_train, spread_train, volatility_train, trajectory_length=16).as_dataloader(\n",
    "    batch_size=8, \n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    prefetch_factor=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_trajectory_loader = TrajectoryDataset(X_test, next_return_test, spread_test, volatility_test, trajectory_length=16).as_dataloader(\n",
    "    batch_size=8, \n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    prefetch_factor=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e041b148-50dc-4ca0-88cb-43761885bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PortfolioEnvironment(\n",
    "    reward_function=EstimatedReturnReward(fee=0.0, spread_multiplier=0.99),\n",
    ")\n",
    "\n",
    "backend = FullyConnectedBackend(\n",
    "    n_assets=len(config.data_config.symbol_or_symbols),\n",
    "    hidden_dim=128,\n",
    "    num_layers=2, \n",
    "    dropout=0.1,\n",
    "    use_layer_norm=False,\n",
    ")\n",
    "\n",
    "actor = RlActor(\n",
    "    model, \n",
    "    backend,\n",
    "    n_assets=len(config.data_config.symbol_or_symbols),\n",
    "    train_signal_predictor=False, \n",
    "    exploration_eps=0.0\n",
    ").to(device)\n",
    "\n",
    "signal_predictor_actor = SignalPredictorActor(\n",
    "    model, \n",
    "    trade_asset_count=1,\n",
    "    train_signal_predictor=False\n",
    ").to(device)\n",
    "\n",
    "rl_agent = RlAgent(\n",
    "    actor, \n",
    "    env,\n",
    "    single_action_per_trajectory=False\n",
    ")\n",
    "\n",
    "metrics_calculator = MetricsCalculator(\n",
    "    metrics=DEFAULT_METRICS\n",
    ")\n",
    "\n",
    "policy_gradient = PolicyGradient(\n",
    "    rl_agent, \n",
    "    train_trajectory_loader, \n",
    "    val_trajectory_loader, \n",
    "    metrics_calculator=metrics_calculator,\n",
    "    optimizer=torch.optim.AdamW(\n",
    "        [p for p in actor.parameters() if p.requires_grad], \n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-5,\n",
    "        amsgrad=True),\n",
    "    scheduler=None,\n",
    "    loss_fn=SumLogReturnLoss(use_baseline=False),\n",
    "    num_epochs=10,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fa8dec5-eaf9-4f91-af35-30ea24c0e174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 16:32:01,912 - INFO - [PolicyGradient] [VAL] Epoch 0/10 — CumulativeReturn: 0.4364, MeanReturnPercentage: 0.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PolicyGradient] [VAL] Epoch 0/10 — Loss: -0.0453\n"
     ]
    }
   ],
   "source": [
    "epoch_loss, realized_returns_signal_predictor, actions_signal_predictor = policy_gradient.evaluate(signal_predictor_actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c7dcead-f58a-4306-84ab-9ca83cfb332c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't subtract offset-naive and offset-aware datetimes",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplot_cumulative_wealth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturns_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSignal Predictor\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealized_returns_signal_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_set_last_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/intraday-portfolio-management/modeling/rl/visualization/wealth_plot.py:10\u001b[39m, in \u001b[36mplot_cumulative_wealth\u001b[39m\u001b[34m(returns_dict, start_time, end_time)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_cumulative_wealth\u001b[39m(returns_dict: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]], start_time: datetime, end_time: datetime):\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Create uniform datetime range\u001b[39;00m\n\u001b[32m      8\u001b[39m     n_points = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(returns_dict.values())))  \u001b[38;5;66;03m# get length from any series\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     time_points = \u001b[43m[\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Initial wealth\u001b[39;00m\n\u001b[32m     16\u001b[39m     initial_wealth = \u001b[32m1.0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/intraday-portfolio-management/modeling/rl/visualization/wealth_plot.py:11\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_cumulative_wealth\u001b[39m(returns_dict: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]], start_time: datetime, end_time: datetime):\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Create uniform datetime range\u001b[39;00m\n\u001b[32m      8\u001b[39m     n_points = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(returns_dict.values())))  \u001b[38;5;66;03m# get length from any series\u001b[39;00m\n\u001b[32m     10\u001b[39m     time_points = [\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m         start_time + i * (\u001b[43mend_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m) / (n_points - \u001b[32m1\u001b[39m)\n\u001b[32m     12\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_points)\n\u001b[32m     13\u001b[39m     ]\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Initial wealth\u001b[39;00m\n\u001b[32m     16\u001b[39m     initial_wealth = \u001b[32m1.0\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: can't subtract offset-naive and offset-aware datetimes"
     ]
    }
   ],
   "source": [
    "plot_cumulative_wealth(\n",
    "    returns_dict={\n",
    "        'Signal Predictor': realized_returns_signal_predictor,\n",
    "    }, \n",
    "    start_time=config.data_config.train_set_last_date, \n",
    "    end_time=config.data_config.end\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9955c8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy  # Local import to avoid polluting global namespace unnecessarily\n",
    "state_dict = (\n",
    "    model.module.state_dict()\n",
    "        if isinstance(model, torch.nn.DataParallel)\n",
    "    else model.state_dict()\n",
    ")\n",
    "\n",
    "# Keep a local copy of the best weights so we can return the best model\n",
    "# after training finishes, without needing to reload from disk.\n",
    "best_model_state = copy.deepcopy(state_dict)\n",
    "\n",
    "# Persist to disk if a save_path was provided\n",
    "torch.save(state_dict, \"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed829636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 15:35:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'LSTM Default' already exists. Creating a new version of this model...\n",
      "2025/06/26 15:35:14 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LSTM Default, version 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run gentle-loon-699 at: http://127.0.0.1:8080/#/experiments/439216085822475480/runs/54deb1104660468d9ffb4e7e278e9cfb\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/439216085822475480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '10' of model 'LSTM Default'.\n"
     ]
    }
   ],
   "source": [
    "log_experiment(\n",
    "    config=config, \n",
    "    model=model, \n",
    "    history=history,\n",
    "    input_data_sample=next(iter(train_loader))[0].to(trainer.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c286205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9435\n",
      "[LightGBM] [Info] Number of data points in the train set: 7371, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 0.497863\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Train rmse: 0.26411260601695974, Test rmse: 0.2684210886033184, Baseline rmse: 0.2599985897541046\n",
      "Expected return: 0.00010183148393891163, Baseline return: 2.569958041931386e-06, Max possible return 0.00048079571570269763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "evaluate_lgb_regressor(X_train, y_train, X_test, y_test, next_return_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
