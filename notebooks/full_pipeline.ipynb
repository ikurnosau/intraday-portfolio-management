{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3a6dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Format for the log messages\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Log to the console\n",
    "    ]\n",
    ")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from data.raw.retrievers.alpaca_markets_retriever import AlpacaMarketsRetriever\n",
    "from config.constants import *\n",
    "from data.processed.dataset_creation import DatasetCreator\n",
    "from data.processed.indicators import *\n",
    "from data.processed.targets import Balanced3ClassClassification\n",
    "from data.processed.normalization import ZScoreOverWindowNormalizer, ZScoreNormalizer, MinMaxNormalizer\n",
    "from data.processed.dataset_pytorch import DatasetPytorch\n",
    "from modeling.trainer import Trainer\n",
    "from modeling.evaluate import evaluate_lgb_regressor, evaluate_torch_regressor, evaluate_torch_regressor_multiasset\n",
    "from observability.mlflow_integration import log_experiment\n",
    "\n",
    "from config.experiments.cur_experiment import config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "755a729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = AlpacaMarketsRetriever()\n",
    "\n",
    "retrieval_result = retriever.bars(\n",
    "    symbol_or_symbols=config.data_config.symbol_or_symbols, \n",
    "    start=config.data_config.start, \n",
    "    end=config.data_config.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d48d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:16:43,107 - INFO - Processing AAPL …\n",
      "2025-07-01 19:16:43,410 - INFO - Imputing 496 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:16:45,213 - INFO - Processing ADBE …\n",
      "2025-07-01 19:16:45,441 - INFO - Imputing 5392 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:16:47,202 - INFO - Processing ADI …\n",
      "2025-07-01 19:16:47,436 - INFO - Imputing 6204 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:16:49,265 - INFO - Processing AMAT …\n",
      "2025-07-01 19:16:49,497 - INFO - Imputing 4035 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:16:51,264 - INFO - Processing AMD …\n",
      "2025-07-01 19:16:51,530 - INFO - Imputing 214 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:16:53,283 - INFO - Processing ANET …\n",
      "2025-07-01 19:16:53,514 - INFO - Imputing 5097 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:16:55,262 - INFO - Processing AVGO …\n",
      "2025-07-01 19:16:55,525 - INFO - Imputing 1059 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:16:57,279 - INFO - Processing CDNS …\n",
      "2025-07-01 19:16:57,514 - INFO - Imputing 9038 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:16:59,277 - INFO - Processing CRM …\n",
      "2025-07-01 19:16:59,494 - INFO - Imputing 3774 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:01,280 - INFO - Processing CRWD …\n",
      "2025-07-01 19:17:01,550 - INFO - Imputing 4120 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:03,303 - INFO - Processing CSCO …\n",
      "2025-07-01 19:17:03,514 - INFO - Imputing 3929 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:05,254 - INFO - Processing DDOG …\n",
      "2025-07-01 19:17:05,477 - INFO - Imputing 4855 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:07,250 - INFO - Processing DELL …\n",
      "2025-07-01 19:17:07,684 - INFO - Imputing 2432 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:09,423 - INFO - Processing FTNT …\n",
      "2025-07-01 19:17:09,644 - INFO - Imputing 4760 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:11,405 - INFO - Processing GOOGL …\n",
      "2025-07-01 19:17:11,658 - INFO - Imputing 877 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:13,405 - INFO - Processing GOOG …\n",
      "2025-07-01 19:17:13,639 - INFO - Imputing 1161 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:15,382 - INFO - Processing HPQ …\n",
      "2025-07-01 19:17:15,596 - INFO - Imputing 5057 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:17,342 - INFO - Processing IBM …\n",
      "2025-07-01 19:17:17,559 - INFO - Imputing 5038 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:19,316 - INFO - Processing INTC …\n",
      "2025-07-01 19:17:19,583 - INFO - Imputing 215 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:21,322 - INFO - Processing INTU …\n",
      "2025-07-01 19:17:21,549 - INFO - Imputing 12312 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:23,303 - INFO - Processing KLAC …\n",
      "2025-07-01 19:17:23,514 - INFO - Imputing 22343 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:25,267 - INFO - Processing LRCX …\n",
      "2025-07-01 19:17:25,495 - INFO - Imputing 8026 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:27,250 - INFO - Processing MCHP …\n",
      "2025-07-01 19:17:27,469 - INFO - Imputing 4728 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:29,271 - INFO - Processing MDB …\n",
      "2025-07-01 19:17:29,500 - INFO - Imputing 9730 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:31,237 - INFO - Processing META …\n",
      "2025-07-01 19:17:31,488 - INFO - Imputing 1465 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:33,274 - INFO - Processing MRVL …\n",
      "2025-07-01 19:17:33,515 - INFO - Imputing 2386 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:35,297 - INFO - Processing MSFT …\n",
      "2025-07-01 19:17:35,542 - INFO - Imputing 1493 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:37,386 - INFO - Processing MU …\n",
      "2025-07-01 19:17:37,645 - INFO - Imputing 838 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:39,538 - INFO - Processing NET …\n",
      "2025-07-01 19:17:39,778 - INFO - Imputing 5550 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:41,594 - INFO - Processing NOW …\n",
      "2025-07-01 19:17:41,842 - INFO - Imputing 13543 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:43,653 - INFO - Processing NVDA …\n",
      "2025-07-01 19:17:43,945 - INFO - Imputing 1 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:45,699 - INFO - Processing NXPI …\n",
      "2025-07-01 19:17:45,928 - INFO - Imputing 7743 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:47,689 - INFO - Processing OKTA …\n",
      "2025-07-01 19:17:47,944 - INFO - Imputing 6551 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:49,727 - INFO - Processing ON …\n",
      "2025-07-01 19:17:49,941 - INFO - Imputing 4325 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:51,721 - INFO - Processing ORCL …\n",
      "2025-07-01 19:17:51,939 - INFO - Imputing 3440 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:53,732 - INFO - Processing PANW …\n",
      "2025-07-01 19:17:54,157 - INFO - Imputing 4966 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:55,903 - INFO - Processing PLTR …\n",
      "2025-07-01 19:17:56,183 - INFO - Imputing 58 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:17:57,960 - INFO - Processing PYPL …\n",
      "2025-07-01 19:17:58,247 - INFO - Imputing 3097 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:18:00,028 - INFO - Processing QCOM …\n",
      "2025-07-01 19:18:00,245 - INFO - Imputing 3487 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:18:02,014 - INFO - Processing SHOP …\n",
      "2025-07-01 19:18:02,247 - INFO - Imputing 3314 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:18:04,020 - INFO - Processing SMCI …\n",
      "2025-07-01 19:18:04,266 - INFO - Imputing 242 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:18:06,032 - INFO - Processing SNOW …\n",
      "2025-07-01 19:18:06,266 - INFO - Imputing 3001 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:18:08,018 - INFO - Processing SNPS …\n",
      "2025-07-01 19:18:08,235 - INFO - Imputing 18331 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:18:09,987 - INFO - Processing SQ …\n",
      "2025-07-01 19:18:10,137 - INFO - Imputing 1647 NaN rows out of 61778 with forward fill..\n",
      "2025-07-01 19:18:11,288 - INFO - SQ has 55457 rows, but 87398 are expected. Skipping …\n",
      "2025-07-01 19:18:11,288 - INFO - Processing STX …\n",
      "2025-07-01 19:18:11,506 - INFO - Imputing 6823 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:18:13,263 - INFO - Processing TEAM …\n",
      "2025-07-01 19:18:13,491 - INFO - Imputing 8239 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:18:15,242 - INFO - Processing TSM …\n",
      "2025-07-01 19:18:15,492 - INFO - Imputing 1209 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:18:17,262 - INFO - Processing TXN …\n",
      "2025-07-01 19:18:17,487 - INFO - Imputing 5080 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:18:19,312 - INFO - Processing WDC …\n",
      "2025-07-01 19:18:19,560 - INFO - Imputing 5012 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:18:21,330 - INFO - Processing ZS …\n",
      "2025-07-01 19:18:21,569 - INFO - Imputing 8329 NaN rows out of 97359 with forward fill..\n",
      "2025-07-01 19:18:23,334 - INFO - Finished feature generation. 1 assets skipped due to insufficient rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((49, 79999, 30, 37),\n",
       " (49, 79999),\n",
       " (49, 79999),\n",
       " (49, 7341, 30, 37),\n",
       " (49, 7341),\n",
       " (49, 7341))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_creator = DatasetCreator(\n",
    "    features=config.data_config.features,\n",
    "    target=config.data_config.target,\n",
    "    normalizer=config.data_config.normalizer,\n",
    "    missing_values_handler=config.data_config.missing_values_handler,\n",
    "    train_set_last_date=config.data_config.train_set_last_date, \n",
    "    in_seq_len=config.data_config.in_seq_len,\n",
    "    multi_asset_prediction=config.data_config.multi_asset_prediction,\n",
    ")\n",
    "\n",
    "X_train, y_train, next_return_train, X_test, y_test, next_return_test = dataset_creator.create_dataset_numpy(retrieval_result)\n",
    "X_train.shape, y_train.shape, next_return_train.shape, X_test.shape, y_test.shape, next_return_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f50717e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((79999, 49, 30, 37),\n",
       " (79999, 49),\n",
       " (79999, 49),\n",
       " (7341, 49, 30, 37),\n",
       " (7341, 49),\n",
       " (7341, 49))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if config.data_config.multi_asset_prediction:\n",
    "    X_train = np.swapaxes(X_train, 0, 1)\n",
    "    y_train = np.swapaxes(y_train, 0, 1)\n",
    "    next_return_train = np.swapaxes(next_return_train, 0, 1)\n",
    "\n",
    "    X_test = np.swapaxes(X_test, 0, 1)\n",
    "    y_test = np.swapaxes(y_test, 0, 1)\n",
    "    next_return_test = np.swapaxes(next_return_test, 0, 1)\n",
    "\n",
    "X_train.shape, y_train.shape, next_return_train.shape, X_test.shape, y_test.shape, next_return_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc91696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.50199676, 0.5025806)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b98a4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DatasetPytorch(X_train, y_train, learning_task='regression').as_dataloader(\n",
    "    batch_size=config.data_config.batch_size,\n",
    "    shuffle=config.data_config.shuffle,\n",
    ")\n",
    "test_loader = DatasetPytorch(X_test, y_test, learning_task='regression').as_dataloader(\n",
    "    batch_size=config.data_config.batch_size,\n",
    "    shuffle=config.data_config.shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c4b5aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TemporalSpatial(\n",
       "  (asset_embed): Embedding(49, 16)\n",
       "  (asset_proj): Linear(in_features=16, out_features=128, bias=False)\n",
       "  (lstm): LSTM(37, 64, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (spatial_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = config.model_config.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a3858fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    loss_fn=config.train_config.loss_fn,\n",
    "    optimizer=config.train_config.optimizer,\n",
    "    scheduler=config.train_config.scheduler,\n",
    "    num_epochs=config.train_config.num_epochs,\n",
    "    device=config.train_config.device,\n",
    "    metrics=config.train_config.metrics,\n",
    "    save_path=config.train_config.save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f01c52e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 19:21:22,857 - INFO - Epoch 1/1\n",
      "2025-07-01 19:22:24,968 - INFO - Train Loss: 0.1314          \n",
      "2025-07-01 19:22:24,968 - INFO - Train Rmse: 0.3615\n",
      "2025-07-01 19:22:24,968 - INFO - Val   Loss: 0.1104\n",
      "2025-07-01 19:22:24,969 - INFO - Val   Rmse: 0.3320\n",
      "2025-07-01 19:22:24,969 - INFO - \n"
     ]
    }
   ],
   "source": [
    "model, history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3802d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([127, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([1024, 49, 30, 37])\n",
      "torch.Size([173, 49, 30, 37])\n",
      "Train rmse: 0.3522928059101105, Test rmse: 0.3322025537490845, Baseline rmse: 0.3323450982570648\n",
      "Expected return: 1.8094615874559525e-05, Baseline return: 7.885851118771825e-06, Max possible return 0.0005796058103442192\n"
     ]
    }
   ],
   "source": [
    "evaluate_torch_regressor_multiasset(model, X_train, y_train, X_test, y_test, next_return_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed829636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 15:35:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'LSTM Default' already exists. Creating a new version of this model...\n",
      "2025/06/26 15:35:14 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: LSTM Default, version 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run gentle-loon-699 at: http://127.0.0.1:8080/#/experiments/439216085822475480/runs/54deb1104660468d9ffb4e7e278e9cfb\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/439216085822475480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '10' of model 'LSTM Default'.\n"
     ]
    }
   ],
   "source": [
    "log_experiment(\n",
    "    config=config, \n",
    "    model=model, \n",
    "    history=history,\n",
    "    input_data_sample=next(iter(train_loader))[0].to(trainer.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c286205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9435\n",
      "[LightGBM] [Info] Number of data points in the train set: 7371, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 0.497863\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Train rmse: 0.26411260601695974, Test rmse: 0.2684210886033184, Baseline rmse: 0.2599985897541046\n",
      "Expected return: 0.00010183148393891163, Baseline return: 2.569958041931386e-06, Max possible return 0.00048079571570269763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "evaluate_lgb_regressor(X_train, y_train, X_test, y_test, next_return_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
