{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69413cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ikurnosau\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime, timezone\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Format for the log messages\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Log to the console\n",
    "    ]\n",
    ")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from data.raw.retrievers.alpaca_markets_retriever import AlpacaMarketsRetriever\n",
    "from config.constants import *\n",
    "from data.processed.dataset_creation import DatasetCreator\n",
    "from data.processed.indicators import *\n",
    "from data.processed.targets import Balanced3ClassClassification\n",
    "from data.processed.normalization import ZScoreOverWindowNormalizer, ZScoreNormalizer, MinMaxNormalizer\n",
    "from data.processed.dataset_pytorch import DatasetPytorch\n",
    "from modeling.trainer import Trainer\n",
    "from modeling.evaluate import evaluate_lgb_regressor, evaluate_torch_regressor, evaluate_torch_regressor_multiasset\n",
    "from observability.mlflow_integration import log_experiment\n",
    "\n",
    "from modeling.rl.environment import PortfolioEnvironment\n",
    "from modeling.rl.state import State\n",
    "from modeling.rl.agent import RlAgent\n",
    "from modeling.rl.algorithms.policy_gradient import PolicyGradient\n",
    "from modeling.rl.actors.actor import RlActor\n",
    "from modeling.rl.trajectory_dataset import TrajectoryDataset\n",
    "from modeling.rl.metrics import MetricsCalculator, DEFAULT_METRICS\n",
    "from modeling.rl.reward import estimated_return_reward\n",
    "from modeling.rl.loss import log_cumulative_trajectory_return_loss\n",
    "\n",
    "from config.experiments.cur_experiment import config\n",
    "\n",
    "torch.backends.cudnn.benchmark = config.train_config.cudnn_benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2c2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = AlpacaMarketsRetriever(download_from_gdrive=False)\n",
    "\n",
    "retrieval_result = retriever.bars_with_quotes(\n",
    "    symbol_or_symbols=config.data_config.symbol_or_symbols, \n",
    "    start=config.data_config.start, \n",
    "    end=config.data_config.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81de79a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 15:51:54,632 - INFO - Processing AAPL …\n",
      "2025-07-23 15:51:55,025 - INFO - Imputing 496 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:51:55,386 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:51:55,407 - INFO - Processing AMD …\n",
      "2025-07-23 15:51:55,766 - INFO - Imputing 214 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:51:56,103 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:51:56,123 - INFO - Processing BABA …\n",
      "2025-07-23 15:51:56,733 - INFO - Imputing 874 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:51:57,085 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:51:57,107 - INFO - Processing BITU …\n",
      "2025-07-23 15:51:57,601 - INFO - Imputing 6493 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:51:57,953 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:51:57,973 - INFO - Processing CSCO …\n",
      "2025-07-23 15:51:58,292 - INFO - Imputing 3929 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:51:58,619 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:51:58,639 - INFO - Processing C …\n",
      "2025-07-23 15:51:58,953 - INFO - Imputing 3733 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:51:59,305 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:51:59,325 - INFO - Processing DAL …\n",
      "2025-07-23 15:51:59,652 - INFO - Imputing 4112 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:51:59,993 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:00,015 - INFO - Processing DIA …\n",
      "2025-07-23 15:52:00,345 - INFO - Imputing 3842 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:00,693 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:00,715 - INFO - Processing GLD …\n",
      "2025-07-23 15:52:01,058 - INFO - Imputing 1989 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:01,407 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:01,431 - INFO - Processing GOOG …\n",
      "2025-07-23 15:52:01,791 - INFO - Imputing 1161 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:02,141 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:02,161 - INFO - Processing IJR …\n",
      "2025-07-23 15:52:02,525 - INFO - Imputing 5204 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:02,963 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:02,991 - INFO - Processing MARA …\n",
      "2025-07-23 15:52:03,443 - INFO - Imputing 108 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:03,846 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:03,870 - INFO - Processing MRVL …\n",
      "2025-07-23 15:52:04,361 - INFO - Imputing 2386 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:04,796 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:04,820 - INFO - Processing MU …\n",
      "2025-07-23 15:52:05,280 - INFO - Imputing 838 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:05,958 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:05,983 - INFO - Processing NEE …\n",
      "2025-07-23 15:52:06,413 - INFO - Imputing 4731 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:06,866 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:06,891 - INFO - Processing NKE …\n",
      "2025-07-23 15:52:07,337 - INFO - Imputing 2509 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:07,737 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:07,758 - INFO - Processing NVDA …\n",
      "2025-07-23 15:52:08,227 - INFO - Imputing 1 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:08,613 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:08,634 - INFO - Processing ON …\n",
      "2025-07-23 15:52:09,038 - INFO - Imputing 4325 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:09,484 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:09,518 - INFO - Processing PLTR …\n",
      "2025-07-23 15:52:10,025 - INFO - Imputing 58 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:10,417 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:10,439 - INFO - Processing PYPL …\n",
      "2025-07-23 15:52:10,838 - INFO - Imputing 3097 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:11,230 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:11,252 - INFO - Processing QLD …\n",
      "2025-07-23 15:52:11,580 - INFO - Imputing 4196 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:11,918 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:11,949 - INFO - Processing QQQM …\n",
      "2025-07-23 15:52:12,255 - INFO - Imputing 5090 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:12,568 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:12,586 - INFO - Processing QQQ …\n",
      "2025-07-23 15:52:12,913 - INFO - Imputing 152 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:13,252 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:13,268 - INFO - Processing RKLB …\n",
      "2025-07-23 15:52:13,584 - INFO - Imputing 659 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:13,891 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:13,911 - INFO - Processing RSP …\n",
      "2025-07-23 15:52:14,382 - INFO - Imputing 4643 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:14,696 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:14,713 - INFO - Processing SMCI …\n",
      "2025-07-23 15:52:15,035 - INFO - Imputing 242 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:15,339 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:15,355 - INFO - Processing SMH …\n",
      "2025-07-23 15:52:15,624 - INFO - Imputing 3394 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:15,967 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:15,985 - INFO - Processing SOXL …\n",
      "2025-07-23 15:52:16,341 - INFO - Imputing 17 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:16,650 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:16,670 - INFO - Processing SOXX …\n",
      "2025-07-23 15:52:16,975 - INFO - Imputing 4248 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:17,294 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:17,312 - INFO - Processing SPXL …\n",
      "2025-07-23 15:52:17,624 - INFO - Imputing 2257 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:17,949 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:17,970 - INFO - Processing SPY …\n",
      "2025-07-23 15:52:18,292 - INFO - Imputing 219 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:18,604 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:18,623 - INFO - Processing TMF …\n",
      "2025-07-23 15:52:18,972 - INFO - Imputing 539 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:19,303 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:19,321 - INFO - Processing TNA …\n",
      "2025-07-23 15:52:19,635 - INFO - Imputing 440 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:20,005 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:20,024 - INFO - Processing TQQQ …\n",
      "2025-07-23 15:52:20,380 - INFO - Imputing 37 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:20,696 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:20,715 - INFO - Processing TSLA …\n",
      "2025-07-23 15:52:21,342 - INFO - Imputing 2 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:21,672 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:21,693 - INFO - Processing UBER …\n",
      "2025-07-23 15:52:22,016 - INFO - Imputing 1667 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:22,387 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:22,411 - INFO - Processing UDOW …\n",
      "2025-07-23 15:52:22,756 - INFO - Imputing 5493 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:23,138 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:23,157 - INFO - Processing UPRO …\n",
      "2025-07-23 15:52:23,519 - INFO - Imputing 1797 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:23,877 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:23,896 - INFO - Processing VOO …\n",
      "2025-07-23 15:52:24,258 - INFO - Imputing 2312 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:24,603 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:24,621 - INFO - Processing WFC …\n",
      "2025-07-23 15:52:24,945 - INFO - Imputing 4302 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:25,273 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:25,293 - INFO - Processing XBI …\n",
      "2025-07-23 15:52:25,594 - INFO - Imputing 4076 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:25,947 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:25,970 - INFO - Processing XLC …\n",
      "2025-07-23 15:52:26,339 - INFO - Imputing 5351 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:26,657 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:26,676 - INFO - Processing XLE …\n",
      "2025-07-23 15:52:26,982 - INFO - Imputing 3826 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:27,315 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:27,338 - INFO - Processing XLI …\n",
      "2025-07-23 15:52:27,650 - INFO - Imputing 5077 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:28,003 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:28,023 - INFO - Processing XLK …\n",
      "2025-07-23 15:52:28,378 - INFO - Imputing 4014 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:28,745 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:28,762 - INFO - Processing XLU …\n",
      "2025-07-23 15:52:29,049 - INFO - Imputing 4835 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:29,416 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:29,432 - INFO - Processing XLV …\n",
      "2025-07-23 15:52:29,742 - INFO - Imputing 4922 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:30,117 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:30,140 - INFO - Processing XLY …\n",
      "2025-07-23 15:52:30,816 - INFO - Imputing 5146 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:31,256 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:31,277 - INFO - Processing XOM …\n",
      "2025-07-23 15:52:31,786 - INFO - Imputing 3570 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:32,296 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:32,317 - INFO - Processing XRT …\n",
      "2025-07-23 15:52:32,607 - INFO - Imputing 5599 NaN rows out of 97359 with forward fill..\n",
      "2025-07-23 15:52:32,946 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-23 15:52:32,967 - INFO - Finished feature generation. 0 assets skipped due to insufficient rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((79909, 50, 120, 15),\n",
       " (79909, 50),\n",
       " (79909, 50),\n",
       " (79909, 50),\n",
       " (7251, 50, 120, 15),\n",
       " (7251, 50),\n",
       " (7251, 50),\n",
       " (7251, 50))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_creator = DatasetCreator(\n",
    "    features=config.data_config.features,\n",
    "    target=config.data_config.target,\n",
    "    normalizer=config.data_config.normalizer,\n",
    "    missing_values_handler=config.data_config.missing_values_handler,\n",
    "    train_set_last_date=config.data_config.train_set_last_date, \n",
    "    in_seq_len=config.data_config.in_seq_len,\n",
    "    multi_asset_prediction=config.data_config.multi_asset_prediction,\n",
    ")\n",
    "\n",
    "X_train, y_train, next_return_train, spread_train, X_test, y_test, next_return_test, spread_test = dataset_creator.create_dataset_numpy(retrieval_result)\n",
    "X_train.shape, y_train.shape, next_return_train.shape, spread_train.shape, X_test.shape, y_test.shape, next_return_test.shape, spread_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c28a1e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trajectory_loader = TrajectoryDataset(X_train, next_return_train, spread_train, trajectory_length=16).as_dataloader(\n",
    "    batch_size=8, \n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    prefetch_factor=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_trajectory_loader = TrajectoryDataset(X_test, next_return_test, spread_test, trajectory_length=16).as_dataloader(\n",
    "    batch_size=8, \n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    "    prefetch_factor=4,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf1089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PortfolioEnvironment(\n",
    "    reward_function=estimated_return_reward,\n",
    "    transaction_fee=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "989abaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ikurnosau\\AppData\\Local\\Temp\\ipykernel_42056\\3648200845.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  signal_predictor.load_state_dict(torch.load('../modeling/checkpoints/best_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TemporalSpatial(\n",
       "  (asset_embed): Embedding(50, 32)\n",
       "  (asset_proj): Linear(in_features=32, out_features=512, bias=False)\n",
       "  (lstm): LSTM(15, 256, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (spatial_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_predictor = config.model_config.model.to(torch.device('cuda'))\n",
    "signal_predictor.load_state_dict(torch.load('../modeling/checkpoints/best_model.pth'))\n",
    "signal_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff94dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = RlActor(\n",
    "    signal_predictor, \n",
    "    n_assets=len(config.data_config.symbol_or_symbols),\n",
    "    hidden_dim=128,\n",
    "    train_signal_predictor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6462062",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_agent = RlAgent(\n",
    "    actor, \n",
    "    env\n",
    ")\n",
    "\n",
    "metrics_calculator = MetricsCalculator(\n",
    "    metrics=DEFAULT_METRICS\n",
    ")\n",
    "policy_gradient = PolicyGradient(\n",
    "    rl_agent, \n",
    "    train_trajectory_loader, \n",
    "    val_trajectory_loader, \n",
    "    metrics_calculator=metrics_calculator,\n",
    "    optimizer=torch.optim.Adam([p for p in actor.parameters() if p.requires_grad], lr=1e-3),\n",
    "    scheduler=None,\n",
    "    loss_fn=log_cumulative_trajectory_return_loss,\n",
    "    num_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65ba47e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Couldn't open shared file mapping: <torch_42056_1779087268_1>, error code: <1450>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpolicy_gradient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\Projects\\QuantitativeTrading\\intraday-portfolio-management\\modeling\\rl\\algorithms\\policy_gradient.py:100\u001b[0m, in \u001b[0;36mPolicyGradient.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run training & evaluation loop.\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    giving callers flexibility to override it on demand.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs):\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# --- Training phase ---\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# --- Validation phase ---\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_epoch(epoch)\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\Projects\\QuantitativeTrading\\intraday-portfolio-management\\modeling\\rl\\algorithms\\policy_gradient.py:141\u001b[0m, in \u001b[0;36mPolicyGradient.train_epoch\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m, epoch: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# Training mode\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m--> 141\u001b[0m     epoch_loss, realized_returns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[PolicyGradient] Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m — Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m realized_returns:\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\Projects\\QuantitativeTrading\\intraday-portfolio-management\\modeling\\rl\\algorithms\\policy_gradient.py:54\u001b[0m, in \u001b[0;36mPolicyGradient._run_epoch\u001b[1;34m(self, data_loader, epoch, epochs, training)\u001b[0m\n\u001b[0;32m     47\u001b[0m realized_returns: List[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad() \u001b[38;5;28;01mif\u001b[39;00m training \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignal_features_trajectory_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnext_returns_trajectory_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspreads_trajectory_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m---> 54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m Epoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepochs\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_trajectory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[43msignal_features_trajectory_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignal_features_trajectory_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnext_returns_trajectory_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnext_returns_trajectory_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspreads_trajectory_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspreads_trajectory_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:479\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpersistent_workers \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 479\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\u001b[38;5;241m.\u001b[39m_reset(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:415\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1138\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1131\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1138\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\multiprocessing\\context.py:337\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     97\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\multiprocessing\\reductions.py:607\u001b[0m, in \u001b[0;36mreduce_storage\u001b[1;34m(storage)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot pickle meta storage; try pickling a meta tensor instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m get_sharing_strategy() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_system\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 607\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_share_filename_cpu_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m     cache_key \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    609\u001b[0m     rebuild \u001b[38;5;241m=\u001b[39m rebuild_storage_filename\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\storage.py:437\u001b[0m, in \u001b[0;36m_share_memory_lock_protected.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;66;03m# If we acquired the storage lock here and we're done working on it\u001b[39;00m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;66;03m# we can now release it and free the entry.\u001b[39;00m\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m to_free \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;66;03m# Ensure that the cdata from the storage didn't change and only\u001b[39;00m\n\u001b[0;32m    443\u001b[0m         \u001b[38;5;66;03m# the data_ptr did.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\storage.py:516\u001b[0m, in \u001b[0;36mUntypedStorage._share_filename_cpu_\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;129m@_share_memory_lock_protected\u001b[39m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_share_filename_cpu_\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_share_filename_cpu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Couldn't open shared file mapping: <torch_42056_1779087268_1>, error code: <1450>"
     ]
    }
   ],
   "source": [
    "policy_gradient.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967ed1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
