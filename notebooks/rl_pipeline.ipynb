{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69413cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ikurnosau\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime, timezone\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Format for the log messages\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Log to the console\n",
    "    ]\n",
    ")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from data.raw.retrievers.alpaca_markets_retriever import AlpacaMarketsRetriever\n",
    "from config.constants import *\n",
    "from data.processed.dataset_creation import DatasetCreator\n",
    "from data.processed.indicators import *\n",
    "from data.processed.targets import Balanced3ClassClassification\n",
    "from data.processed.normalization import ZScoreOverWindowNormalizer, ZScoreNormalizer, MinMaxNormalizer\n",
    "from data.processed.dataset_pytorch import DatasetPytorch\n",
    "from modeling.trainer import Trainer\n",
    "from modeling.evaluate import evaluate_lgb_regressor, evaluate_torch_regressor, evaluate_torch_regressor_multiasset\n",
    "from observability.mlflow_integration import log_experiment\n",
    "\n",
    "from modeling.rl.environment import PortfolioEnvironment\n",
    "from modeling.rl.state import State\n",
    "from modeling.rl.agent import RlAgent\n",
    "from modeling.rl.algorithms.policy_gradient import PolicyGradient\n",
    "from modeling.rl.actors.actor import RlActor\n",
    "\n",
    "from config.experiments.cur_experiment import config\n",
    "\n",
    "torch.backends.cudnn.benchmark = config.train_config.cudnn_benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2c2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = AlpacaMarketsRetriever(download_from_gdrive=False)\n",
    "\n",
    "retrieval_result = retriever.bars_with_quotes(\n",
    "    symbol_or_symbols=config.data_config.symbol_or_symbols, \n",
    "    start=config.data_config.start, \n",
    "    end=config.data_config.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e2ed06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_trading_days(retrieval_result) -> list[datetime.date]:\n",
    "    \"\"\"Enumerate all distinct trading days in *retrieval_result*.\"\"\"\n",
    "    days = set()\n",
    "    for df in retrieval_result.values():\n",
    "        days.update(pd.to_datetime(df[\"date\"]).dt.date.unique())\n",
    "    return sorted(days)\n",
    "\n",
    "trading_days = get_trading_days(retrieval_result)\n",
    "len(trading_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81de79a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 15:21:31,793 - INFO - Processing AAPL …\n",
      "2025-07-18 15:21:32,700 - INFO - Imputing 496 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:33,271 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:33,304 - INFO - Processing AMD …\n",
      "2025-07-18 15:21:33,920 - INFO - Imputing 214 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:34,516 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:34,547 - INFO - Processing BABA …\n",
      "2025-07-18 15:21:35,173 - INFO - Imputing 874 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:35,756 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:35,790 - INFO - Processing BITU …\n",
      "2025-07-18 15:21:36,391 - INFO - Imputing 6493 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:36,988 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:37,020 - INFO - Processing CSCO …\n",
      "2025-07-18 15:21:37,601 - INFO - Imputing 3929 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:38,163 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:38,196 - INFO - Processing C …\n",
      "2025-07-18 15:21:38,719 - INFO - Imputing 3733 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:39,302 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:39,336 - INFO - Processing DAL …\n",
      "2025-07-18 15:21:39,862 - INFO - Imputing 4112 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:40,447 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:40,478 - INFO - Processing DIA …\n",
      "2025-07-18 15:21:41,030 - INFO - Imputing 3842 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:41,601 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:41,637 - INFO - Processing GLD …\n",
      "2025-07-18 15:21:42,200 - INFO - Imputing 1989 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:42,768 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:42,800 - INFO - Processing GOOG …\n",
      "2025-07-18 15:21:43,389 - INFO - Imputing 1161 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:43,982 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:44,013 - INFO - Processing IJR …\n",
      "2025-07-18 15:21:44,525 - INFO - Imputing 5204 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:45,112 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:45,141 - INFO - Processing MARA …\n",
      "2025-07-18 15:21:45,765 - INFO - Imputing 108 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:46,362 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:46,393 - INFO - Processing MRVL …\n",
      "2025-07-18 15:21:47,220 - INFO - Imputing 2386 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:47,800 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:47,831 - INFO - Processing MU …\n",
      "2025-07-18 15:21:48,444 - INFO - Imputing 838 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:49,039 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:49,069 - INFO - Processing NEE …\n",
      "2025-07-18 15:21:49,597 - INFO - Imputing 4731 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:50,186 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:50,212 - INFO - Processing NKE …\n",
      "2025-07-18 15:21:50,765 - INFO - Imputing 2509 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:51,336 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:51,368 - INFO - Processing NVDA …\n",
      "2025-07-18 15:21:52,016 - INFO - Imputing 1 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:52,595 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:52,626 - INFO - Processing ON …\n",
      "2025-07-18 15:21:53,168 - INFO - Imputing 4325 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:53,762 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:53,792 - INFO - Processing PLTR …\n",
      "2025-07-18 15:21:54,469 - INFO - Imputing 58 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:55,073 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:55,105 - INFO - Processing PYPL …\n",
      "2025-07-18 15:21:55,681 - INFO - Imputing 3097 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:56,244 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:56,275 - INFO - Processing QLD …\n",
      "2025-07-18 15:21:56,907 - INFO - Imputing 4196 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:57,502 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:57,530 - INFO - Processing QQQM …\n",
      "2025-07-18 15:21:58,061 - INFO - Imputing 5090 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:21:58,629 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:21:58,664 - INFO - Processing QQQ …\n",
      "2025-07-18 15:21:59,561 - INFO - Imputing 152 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:00,173 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:00,203 - INFO - Processing RKLB …\n",
      "2025-07-18 15:22:00,809 - INFO - Imputing 659 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:01,411 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:01,444 - INFO - Processing RSP …\n",
      "2025-07-18 15:22:01,977 - INFO - Imputing 4643 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:02,569 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:02,601 - INFO - Processing SMCI …\n",
      "2025-07-18 15:22:03,213 - INFO - Imputing 242 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:03,805 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:03,837 - INFO - Processing SMH …\n",
      "2025-07-18 15:22:04,407 - INFO - Imputing 3394 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:04,954 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:04,985 - INFO - Processing SOXL …\n",
      "2025-07-18 15:22:05,605 - INFO - Imputing 17 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:06,197 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:06,226 - INFO - Processing SOXX …\n",
      "2025-07-18 15:22:06,755 - INFO - Imputing 4248 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:07,314 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:07,341 - INFO - Processing SPXL …\n",
      "2025-07-18 15:22:07,900 - INFO - Imputing 2257 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:08,454 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:08,484 - INFO - Processing SPY …\n",
      "2025-07-18 15:22:09,109 - INFO - Imputing 219 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:09,678 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:09,709 - INFO - Processing TMF …\n",
      "2025-07-18 15:22:10,291 - INFO - Imputing 539 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:10,867 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:10,894 - INFO - Processing TNA …\n",
      "2025-07-18 15:22:11,735 - INFO - Imputing 440 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:12,303 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:12,332 - INFO - Processing TQQQ …\n",
      "2025-07-18 15:22:13,012 - INFO - Imputing 37 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:13,593 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:13,624 - INFO - Processing TSLA …\n",
      "2025-07-18 15:22:14,251 - INFO - Imputing 2 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:14,846 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:14,877 - INFO - Processing UBER …\n",
      "2025-07-18 15:22:15,437 - INFO - Imputing 1667 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:15,995 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:16,025 - INFO - Processing UDOW …\n",
      "2025-07-18 15:22:16,566 - INFO - Imputing 5493 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:17,140 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:17,168 - INFO - Processing UPRO …\n",
      "2025-07-18 15:22:17,782 - INFO - Imputing 1797 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:18,362 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:18,397 - INFO - Processing VOO …\n",
      "2025-07-18 15:22:18,946 - INFO - Imputing 2312 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:19,483 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:19,511 - INFO - Processing WFC …\n",
      "2025-07-18 15:22:20,026 - INFO - Imputing 4302 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:20,626 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:20,658 - INFO - Processing XBI …\n",
      "2025-07-18 15:22:21,161 - INFO - Imputing 4076 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:21,727 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:21,756 - INFO - Processing XLC …\n",
      "2025-07-18 15:22:22,268 - INFO - Imputing 5351 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:22,824 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:22,853 - INFO - Processing XLE …\n",
      "2025-07-18 15:22:23,372 - INFO - Imputing 3826 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:23,941 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:23,968 - INFO - Processing XLI …\n",
      "2025-07-18 15:22:24,469 - INFO - Imputing 5077 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:25,036 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:25,063 - INFO - Processing XLK …\n",
      "2025-07-18 15:22:25,833 - INFO - Imputing 4014 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:26,437 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:26,471 - INFO - Processing XLU …\n",
      "2025-07-18 15:22:26,969 - INFO - Imputing 4835 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:27,545 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:27,572 - INFO - Processing XLV …\n",
      "2025-07-18 15:22:28,084 - INFO - Imputing 4922 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:28,632 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:28,662 - INFO - Processing XLY …\n",
      "2025-07-18 15:22:29,163 - INFO - Imputing 5146 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:29,727 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:29,755 - INFO - Processing XOM …\n",
      "2025-07-18 15:22:30,268 - INFO - Imputing 3570 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:30,840 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:30,867 - INFO - Processing XRT …\n",
      "2025-07-18 15:22:31,366 - INFO - Imputing 5599 NaN rows out of 97359 with forward fill..\n",
      "2025-07-18 15:22:31,924 - INFO - Imputing 39 NaN rows with 0.5 sentinel value\n",
      "2025-07-18 15:22:31,956 - INFO - Finished feature generation. 0 assets skipped due to insufficient rows.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((79909, 50, 120, 15),\n",
       " (79909, 50),\n",
       " (79909, 50),\n",
       " (79909, 50),\n",
       " (7251, 50, 120, 15),\n",
       " (7251, 50),\n",
       " (7251, 50),\n",
       " (7251, 50))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_creator = DatasetCreator(\n",
    "    features=config.data_config.features,\n",
    "    target=config.data_config.target,\n",
    "    normalizer=config.data_config.normalizer,\n",
    "    missing_values_handler=config.data_config.missing_values_handler,\n",
    "    train_set_last_date=config.data_config.train_set_last_date, \n",
    "    in_seq_len=config.data_config.in_seq_len,\n",
    "    multi_asset_prediction=config.data_config.multi_asset_prediction,\n",
    ")\n",
    "\n",
    "X_train, y_train, next_return_train, spread_train, X_test, y_test, next_return_test, spread_test = dataset_creator.create_dataset_numpy(retrieval_result)\n",
    "X_train.shape, y_train.shape, next_return_train.shape, spread_train.shape, X_test.shape, y_test.shape, next_return_test.shape, spread_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43a546c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PortfolioEnvironment(X_train, y_train, next_return_train, spread_train, X_test, y_test, next_return_test, spread_test, trading_days, transaction_fee=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "989abaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ikurnosau\\AppData\\Local\\Temp\\ipykernel_27844\\1896325696.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  signal_predictor.load_state_dict(torch.load('best_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TemporalSpatial(\n",
       "  (asset_embed): Embedding(50, 32)\n",
       "  (asset_proj): Linear(in_features=32, out_features=512, bias=False)\n",
       "  (lstm): LSTM(15, 256, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (spatial_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_predictor = config.model_config.model.to(torch.device('cuda'))\n",
    "signal_predictor.load_state_dict(torch.load('best_model.pth'))\n",
    "signal_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eff94dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = RlActor(signal_predictor, n_assets=len(config.data_config.symbol_or_symbols)).to()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6462062",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_agent = RlAgent(actor, env)\n",
    "policy_gradient = PolicyGradient(rl_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65ba47e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-18 16:18:40,158 - INFO - loss: 2.2913924112799577e-05, rewards_t: -2.288945142936427e-05\n",
      "2025-07-18 16:18:55,436 - INFO - loss: 5.428933036455419e-06, rewards_t: -5.427430096460739e-06\n",
      "2025-07-18 16:19:11,699 - INFO - loss: 1.3680518122782814e-06, rewards_t: -1.3631030242322595e-06\n",
      "2025-07-18 16:19:27,887 - INFO - loss: 1.7615773685975e-05, rewards_t: -1.759733095241245e-05\n",
      "2025-07-18 16:19:44,070 - INFO - loss: 8.950911251304206e-06, rewards_t: -8.935324331105221e-06\n",
      "2025-07-18 16:20:00,306 - INFO - loss: -7.663102587684989e-05, rewards_t: 7.772999379085377e-05\n",
      "2025-07-18 16:20:16,875 - INFO - loss: 1.603580244591285e-06, rewards_t: -1.5848758039282984e-06\n",
      "2025-07-18 16:20:34,511 - INFO - loss: -1.4868192010908388e-05, rewards_t: 1.4914343410055153e-05\n",
      "2025-07-18 16:20:53,203 - INFO - loss: 1.4591849321732298e-05, rewards_t: -1.456500103813596e-05\n",
      "2025-07-18 16:21:09,417 - INFO - loss: -1.7759693946572952e-05, rewards_t: 1.7798522094381042e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpolicy_gradient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\Projects\\QuantitativeTrading\\intraday-portfolio-management\\modeling\\rl\\algorithms\\policy_gradient.py:41\u001b[0m, in \u001b[0;36mPolicyGradient.train\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m     39\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m day \u001b[38;5;129;01min\u001b[39;00m trading_days:\n\u001b[1;32m---> 41\u001b[0m     trajectory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_trajectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mday\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trajectory:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\Projects\\QuantitativeTrading\\intraday-portfolio-management\\modeling\\rl\\agent.py:46\u001b[0m, in \u001b[0;36mRlAgent.generate_trajectory\u001b[1;34m(self, day)\u001b[0m\n\u001b[0;32m     44\u001b[0m trajectory \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     step_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\Projects\\QuantitativeTrading\\intraday-portfolio-management\\modeling\\rl\\agent.py:30\u001b[0m, in \u001b[0;36mRlAgent.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrading day not initialised; call set_trading_day first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m reward, next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Episode finished\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\Projects\\QuantitativeTrading\\intraday-portfolio-management\\modeling\\rl\\actors\\actor.py:68\u001b[0m, in \u001b[0;36mRlActor.forward\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     66\u001b[0m x \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39msignal_features\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# (1, feat)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 68\u001b[0m     signal_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignal_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# (feat',)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# extra = torch.stack((state.position, state.spread))  # (2,)\u001b[39;00m\n\u001b[0;32m     71\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_shared(torch\u001b[38;5;241m.\u001b[39mcat([signal_repr, state\u001b[38;5;241m.\u001b[39mposition, state\u001b[38;5;241m.\u001b[39mspread], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# (hidden,)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\Projects\\QuantitativeTrading\\intraday-portfolio-management\\modeling\\models\\tsa_classifier.py:98\u001b[0m, in \u001b[0;36mTemporalSpatial.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# (B*A, T, F_concat) → LSTM → (B*A, H)\u001b[39;00m\n\u001b[0;32m     97\u001b[0m x_flat \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(B \u001b[38;5;241m*\u001b[39m A, T, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 98\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m h \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# last time step (B*A, H)\u001b[39;00m\n\u001b[0;32m    100\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(h)\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1123\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1137\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1145\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "policy_gradient.train(epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967ed1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
