{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b3b0b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "# Disable torch compile for Windows compatibility\n",
    "import torch._dynamo\n",
    "torch._dynamo.config.disable = True\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "import logging\n",
    "import copy\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Format for the log messages\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Log to the console\n",
    "    ]\n",
    ")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from core_data_prep.core_data_prep import DataPreparer\n",
    "from core_data_prep.validations import Validator\n",
    "\n",
    "from data.raw.retrievers.alpaca_markets_retriever import AlpacaMarketsRetriever\n",
    "from data.raw.retrievers.stooq_retriever import StooqRetriever\n",
    "from config.constants import *\n",
    "from data.processed.dataset_creation import DatasetCreator\n",
    "from data.processed.indicators import *\n",
    "from data.processed.targets import Balanced3ClassClassification\n",
    "from data.processed.normalization import ZScoreOverWindowNormalizer, ZScoreNormalizer, MinMaxNormalizer\n",
    "from data.processed.dataset_pytorch import DatasetPytorch\n",
    "from modeling.trainer import Trainer\n",
    "from modeling.evaluate import evaluate_lgb_regressor, evaluate_torch_regressor, evaluate_torch_regressor_multiasset\n",
    "from modeling.modeling_utils import print_model_parameters\n",
    "\n",
    "from modeling.rl.environment import PortfolioEnvironment\n",
    "from modeling.rl.state import State\n",
    "from modeling.rl.agent import RlAgent\n",
    "from modeling.rl.algorithms.policy_gradient import PolicyGradient\n",
    "from modeling.rl.actors.actor import RlActor\n",
    "from modeling.rl.actors.signal_predictor_actor import SignalPredictorActor\n",
    "from modeling.rl.actors.high_energy_low_friction_actor import HighEnergyLowFrictionActor\n",
    "from modeling.rl.actors.xsmom_actor import XSMomActor\n",
    "from modeling.rl.actors.tsmom_actor import TSMomActor\n",
    "from modeling.rl.actors.blsw_actor import BLSWActor\n",
    "from modeling.rl.actors.allocation_propogation_actor import AllocationPropogationActor\n",
    "from modeling.rl.actors.market_actor import MarketActor\n",
    "from modeling.rl.trajectory_dataset import TrajectoryDataset\n",
    "from modeling.rl.metrics import MetricsCalculator, DEFAULT_METRICS\n",
    "from modeling.rl.reward import EstimatedReturnReward\n",
    "from modeling.rl.loss import SumLogReturnLoss, ReinforceLoss\n",
    "from modeling.rl.visualization.wealth_plot import plot_cumulative_wealth\n",
    "from modeling.rl.visualization.position_plot import plot_position_heatmap\n",
    "from config.experiments.cur_experiment import config\n",
    "\n",
    "torch.backends.cudnn.benchmark = config.train_config.cudnn_benchmark\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca58a1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1Day'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(config.data_config.frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2a0de07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retriever = config.data_config.retriever\n",
    "initial_state = config.model_config.model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef589a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_signal_predictor(symbols: list[str], end_date: datetime, train_set_last_date: datetime, val_set_last_date: datetime, model=None):\n",
    "    print(f'Running experiment for {config.data_config.start} to {end_date} with train set last date {train_set_last_date} and val set last date {val_set_last_date}')\n",
    "    \n",
    "    retrieval_result = retriever.bars_with_quotes(symbol_or_symbols=symbols, start=config.data_config.start, end=end_date)\n",
    "\n",
    "    data_preparer = DataPreparer(\n",
    "        normalizer=config.data_config.normalizer,\n",
    "        missing_values_handler=config.data_config.missing_values_handler_polars,\n",
    "        in_seq_len=config.data_config.in_seq_len,\n",
    "        frequency=str(config.data_config.frequency),\n",
    "        validator=config.data_config.validator,\n",
    "    )\n",
    "\n",
    "    (X_train, y_train, statistics_train), (X_val, y_val, statistics_val), (X_test, y_test, statistics_test) = \\\n",
    "        data_preparer.get_experiment_data(\n",
    "            data=retrieval_result,\n",
    "            start_date=None,\n",
    "            end_date=None,\n",
    "            features=config.data_config.features_polars,\n",
    "            statistics=config.data_config.statistics,\n",
    "            target=config.data_config.target,\n",
    "            train_set_last_date=train_set_last_date,\n",
    "            val_set_last_date=val_set_last_date,\n",
    "        )\n",
    "    next_return_train, spread_train, volatility_train, \\\n",
    "        next_return_val, spread_val, volatility_val, \\\n",
    "        next_return_test, spread_test, volatility_test = \\\n",
    "            statistics_train['next_return'], statistics_train['spread'], statistics_train['volatility'], \\\n",
    "            statistics_val['next_return'], statistics_val['spread'], statistics_val['volatility'], \\\n",
    "            statistics_test['next_return'], statistics_test['spread'], statistics_test['volatility']\n",
    "        \n",
    "    print(X_train.shape, y_train.shape, next_return_train.shape, spread_train.shape, volatility_train.shape, X_test.shape,\\\n",
    "         y_test.shape, next_return_test.shape, spread_test.shape, volatility_test.shape)\n",
    "\n",
    "    if not model: \n",
    "        print('Training model...')\n",
    "        train_loader = DatasetPytorch(X_train, y_train, learning_task='regression').as_dataloader(\n",
    "            batch_size=config.train_config.batch_size,\n",
    "            shuffle=config.train_config.shuffle,\n",
    "            num_workers=config.train_config.num_workers,\n",
    "            prefetch_factor=config.train_config.prefetch_factor,\n",
    "            pin_memory=config.train_config.pin_memory,\n",
    "            persistent_workers=config.train_config.persistent_workers,\n",
    "            drop_last=config.train_config.drop_last\n",
    "        )\n",
    "        val_loader = DatasetPytorch(X_val, y_val, learning_task='regression').as_dataloader(\n",
    "            batch_size=config.train_config.batch_size,\n",
    "            shuffle=config.train_config.shuffle,\n",
    "            num_workers=config.train_config.num_workers,\n",
    "            prefetch_factor=config.train_config.prefetch_factor,\n",
    "            pin_memory=config.train_config.pin_memory,\n",
    "            persistent_workers=config.train_config.persistent_workers,\n",
    "            drop_last=config.train_config.drop_last\n",
    "        )\n",
    "\n",
    "        model = config.model_config.model\n",
    "        model.load_state_dict(initial_state)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            loss_fn=config.train_config.loss_fn,\n",
    "            optimizer=config.train_config.optimizer,\n",
    "            scheduler=config.train_config.scheduler,\n",
    "            num_epochs=config.train_config.num_epochs,\n",
    "            early_stopping_patience=config.train_config.early_stopping_patience,\n",
    "            device=config.train_config.device,\n",
    "            metrics=config.train_config.metrics,\n",
    "            save_path=config.train_config.save_path\n",
    "        )\n",
    "\n",
    "        model, history = trainer.train()\n",
    "    else: \n",
    "        print('Using existing model...')\n",
    "\n",
    "    test_trajectory_loader = TrajectoryDataset(X_test, next_return_test, spread_test, volatility_test, \\\n",
    "            trajectory_length=config.rl_config.trajectory_length, horizon=config.data_config.horizon).as_dataloader(\n",
    "        batch_size=1, \n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "        prefetch_factor=4,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    env = PortfolioEnvironment(\n",
    "        reward_function=EstimatedReturnReward(fee=config.rl_config.fee, spread_multiplier=config.rl_config.spread_multiplier),\n",
    "    )\n",
    "\n",
    "    actor = RlActor(\n",
    "        copy.deepcopy(model), \n",
    "        n_assets=len(config.data_config.symbol_or_symbols),\n",
    "        train_signal_predictor=False, \n",
    "    ).to(device)\n",
    "\n",
    "    # signal_predictor_actor = SignalPredictorActor(\n",
    "    #     copy.deepcopy(model), \n",
    "    #     trade_asset_count=config.rl_config.trade_asset_count,\n",
    "    #     train_signal_predictor=False\n",
    "    # ).to(device)\n",
    "\n",
    "    eval_actor = AllocationPropogationActor(\n",
    "        copy.deepcopy(model), \n",
    "        train_allocator=False\n",
    "    ).to(device)\n",
    "\n",
    "    # eval_actor = MarketActor().to(device)\n",
    "\n",
    "    rl_agent = RlAgent(\n",
    "        actor, \n",
    "        env\n",
    "    )\n",
    "\n",
    "    metrics_calculator = MetricsCalculator(\n",
    "        metrics=DEFAULT_METRICS\n",
    "    )\n",
    "\n",
    "    policy_gradient = PolicyGradient(\n",
    "        rl_agent, \n",
    "        None, \n",
    "        test_trajectory_loader, \n",
    "        metrics_calculator=metrics_calculator,\n",
    "        optimizer=torch.optim.AdamW(\n",
    "            [p for p in actor.parameters() if p.requires_grad], \n",
    "            lr=1e-3,\n",
    "            weight_decay=1e-5,\n",
    "            amsgrad=True),\n",
    "        scheduler=None,\n",
    "        loss_fn=ReinforceLoss(use_baseline=False),\n",
    "        num_epochs=10,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    epoch_loss, realized_returns_signal_predictor, actions_signal_predictor = policy_gradient.evaluate(eval_actor, test_trajectory_loader)\n",
    "    return actions_signal_predictor, realized_returns_signal_predictor, model, min(history['val_loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cedb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_end_last_train_dates = [\n",
    "#     {'end': datetime(2011, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2010, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2008, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2012, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2011, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2009, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2013, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2012, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2010, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2014, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2013, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2011, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2015, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2014, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2012, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2016, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2015, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2013, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2017, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2016, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2014, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2018, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2017, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2015, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2019, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2018, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2016, 1, 1, tzinfo=timezone.utc)},\n",
    "# ]\n",
    "# start_end_last_train_dates = [\n",
    "#     {'end': datetime(2010, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2009, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2008, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2011, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2010, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2009, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2012, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2011, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2010, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2013, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2012, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2011, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2014, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2013, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2012, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2015, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2014, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2013, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2016, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2015, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2014, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2017, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2016, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2015, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2018, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2017, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2016, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2019, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2018, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2017, 1, 1, tzinfo=timezone.utc)},\n",
    "# ]\n",
    "# start_end_last_train_dates = [\n",
    "#     {'end': datetime(2001, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2000, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(1999, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2002, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2001, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2000, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2004, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2002, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2000, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2006, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2004, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2002, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2008, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2006, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2004, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2010, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2008, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2006, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2012, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2010, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2008, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2014, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2012, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2010, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2019, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2014, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2012, 1, 1, tzinfo=timezone.utc)},\n",
    "# ]\n",
    "# start_end_last_train_dates = [\n",
    "#     {'end': datetime(2000, 7, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2000, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(1999, 7, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2001, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2000, 7, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2000, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2001, 7, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2001, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2000, 7, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2002, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2001, 7, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2001, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2002, 7, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2002, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2001, 7, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2003, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2002, 7, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2002, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2004, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2003, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2002, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2008, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2004, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2002, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2014, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2008, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2006, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'end': datetime(2019, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2014, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2012, 1, 1, tzinfo=timezone.utc)},\n",
    "# ]\n",
    "\n",
    "# start_end_last_train_dates = [\n",
    "#     {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2004, 4, 8, tzinfo=timezone.utc), 'last_val_date': datetime(2000, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(1999, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2004_2008, 'end': datetime(2008, 2, 19, tzinfo=timezone.utc), 'last_val_date': datetime(2004, 4, 8, tzinfo=timezone.utc), 'last_train_date': datetime(2003, 4, 8, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2008_2008, 'end': datetime(2008, 9, 22, tzinfo=timezone.utc), 'last_val_date': datetime(2008, 2, 19, tzinfo=timezone.utc), 'last_train_date': datetime(2007, 2, 19, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2008_2009, 'end': datetime(2009, 6, 8, tzinfo=timezone.utc), 'last_val_date': datetime(2008, 9, 22, tzinfo=timezone.utc), 'last_train_date': datetime(2007, 9, 22, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2009_2012, 'end': datetime(2012, 9, 24, tzinfo=timezone.utc), 'last_val_date': datetime(2009, 6, 8, tzinfo=timezone.utc), 'last_train_date': datetime(2008, 6, 8, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2012_2013, 'end': datetime(2013, 9, 23, tzinfo=timezone.utc), 'last_val_date': datetime(2012, 9, 24, tzinfo=timezone.utc), 'last_train_date': datetime(2011, 9, 24, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2013_2015, 'end': datetime(2015, 3, 19, tzinfo=timezone.utc), 'last_val_date': datetime(2013, 9, 23, tzinfo=timezone.utc), 'last_train_date': datetime(2012, 9, 23, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2015_2017, 'end': datetime(2017, 3, 19, tzinfo=timezone.utc), 'last_val_date': datetime(2015, 3, 19, tzinfo=timezone.utc), 'last_train_date': datetime(2014, 3, 19, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2017_2018, 'end': datetime(2018, 6, 26, tzinfo=timezone.utc), 'last_val_date': datetime(2017, 9, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2016, 9, 1, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2018_2019, 'end': datetime(2019, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2018, 6, 26, tzinfo=timezone.utc), 'last_train_date': datetime(2017, 6, 26, tzinfo=timezone.utc)},\n",
    "# ]\n",
    "# start_end_last_train_dates = [\n",
    "#     # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2004, 4, 8, tzinfo=timezone.utc), 'last_val_date': datetime(2000, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(1999, 1, 1, tzinfo=timezone.utc)},\n",
    "#     # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2008, 2, 19, tzinfo=timezone.utc), 'last_val_date': datetime(2004, 4, 8, tzinfo=timezone.utc), 'last_train_date': datetime(2003, 4, 8, tzinfo=timezone.utc)},\n",
    "#     # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2008, 9, 22, tzinfo=timezone.utc), 'last_val_date': datetime(2008, 2, 19, tzinfo=timezone.utc), 'last_train_date': datetime(2007, 2, 19, tzinfo=timezone.utc)},\n",
    "#     # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2009, 6, 8, tzinfo=timezone.utc), 'last_val_date': datetime(2008, 9, 22, tzinfo=timezone.utc), 'last_train_date': datetime(2007, 9, 22, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2012, 9, 24, tzinfo=timezone.utc), 'last_val_date': datetime(2009, 6, 8, tzinfo=timezone.utc), 'last_train_date': datetime(2008, 6, 8, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2013, 9, 23, tzinfo=timezone.utc), 'last_val_date': datetime(2012, 9, 24, tzinfo=timezone.utc), 'last_train_date': datetime(2011, 9, 24, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2015, 3, 19, tzinfo=timezone.utc), 'last_val_date': datetime(2013, 9, 23, tzinfo=timezone.utc), 'last_train_date': datetime(2012, 9, 23, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2016, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2015, 3, 19, tzinfo=timezone.utc), 'last_train_date': datetime(2014, 3, 19, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2017, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2016, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2015, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2018, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2017, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2016, 1, 1, tzinfo=timezone.utc)},\n",
    "#     {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2019, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2018, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2018, 7, 1, tzinfo=timezone.utc)},\n",
    "# ]\n",
    "start_end_last_train_dates = [\n",
    "    # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2004, 4, 8, tzinfo=timezone.utc), 'last_val_date': datetime(2000, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(1999, 1, 1, tzinfo=timezone.utc)},\n",
    "    # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2008, 2, 19, tzinfo=timezone.utc), 'last_val_date': datetime(2004, 4, 8, tzinfo=timezone.utc), 'last_train_date': datetime(2003, 4, 8, tzinfo=timezone.utc)},\n",
    "    # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2008, 9, 22, tzinfo=timezone.utc), 'last_val_date': datetime(2008, 2, 19, tzinfo=timezone.utc), 'last_train_date': datetime(2007, 2, 19, tzinfo=timezone.utc)},\n",
    "    # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2009, 6, 8, tzinfo=timezone.utc), 'last_val_date': datetime(2008, 9, 22, tzinfo=timezone.utc), 'last_train_date': datetime(2007, 9, 22, tzinfo=timezone.utc)},\n",
    "    # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2001, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2000, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(1999, 1, 1, tzinfo=timezone.utc)},\n",
    "    # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2002, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2001, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2000, 1, 1, tzinfo=timezone.utc)},\n",
    "    # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2003, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2002, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2001, 1, 1, tzinfo=timezone.utc)},\n",
    "    # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2004, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2003, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2002, 1, 1, tzinfo=timezone.utc)},\n",
    "    # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2005, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2004, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2003, 1, 1, tzinfo=timezone.utc)},\n",
    "    # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2006, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2005, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2004, 1, 1, tzinfo=timezone.utc)},\n",
    "    # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2007, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2006, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2005, 1, 1, tzinfo=timezone.utc)},\n",
    "    # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2008, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2007, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2006, 1, 1, tzinfo=timezone.utc)},\n",
    "    # {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2009, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2008, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2007, 1, 1, tzinfo=timezone.utc)},\n",
    "    \n",
    "    {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2010, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2009, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2008, 1, 1, tzinfo=timezone.utc)},\n",
    "    {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2011, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2010, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2009, 1, 1, tzinfo=timezone.utc)},\n",
    "    {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2012, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2011, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2010, 1, 1, tzinfo=timezone.utc)},\n",
    "    {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2013, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2012, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2011, 1, 1, tzinfo=timezone.utc)},\n",
    "    {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2014, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2013, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2012, 1, 1, tzinfo=timezone.utc)},\n",
    "    {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2015, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2014, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2013, 1, 1, tzinfo=timezone.utc)},\n",
    "    {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2016, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2015, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2014, 1, 1, tzinfo=timezone.utc)},\n",
    "    {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2017, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2016, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2015, 1, 1, tzinfo=timezone.utc)},\n",
    "    {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2018, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2017, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2016, 1, 1, tzinfo=timezone.utc)},\n",
    "    {'symbols': Constants.Data.DJIA_2000_2004, 'end': datetime(2019, 1, 1, tzinfo=timezone.utc), 'last_val_date': datetime(2018, 1, 1, tzinfo=timezone.utc), 'last_train_date': datetime(2017, 7, 1, tzinfo=timezone.utc)},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc9d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for 1970-01-02 00:00:00-05:00 to 2010-01-01 00:00:00+00:00 with train set last date 2008-01-01 00:00:00+00:00 and val set last date 2009-01-01 00:00:00+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:38:00,806 - WARNING - No data found for ek_us_d.csv in root folder\n",
      "2025-12-08 16:38:00,947 - WARNING - No data found for GM between 1970-01-02 00:00:00-05:00 and 2010-01-01 00:00:00+00:00\n",
      "2025-12-08 16:38:03,222 - INFO - retrieved 27 assets\n",
      "2025-12-08 16:38:03,223 - INFO - Using monolithic slices with -60 timestamps\n",
      "2025-12-08 16:38:03,871 - INFO - Found 9589 train slices, 336 val slices, 336 test slices\n",
      "2025-12-08 16:38:03,872 - INFO - Trained per-asset targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13759, 27, 60, 16) (13759, 27) (13759, 27) (13759, 27) (13759, 27) (366, 27, 60, 16) (366, 27) (366, 27) (366, 27) (366, 27)\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:38:17,466 - INFO - Model compiled with torch.compile()\n",
      "2025-12-08 16:38:17,467 - INFO - Epoch 1/20\n",
      "2025-12-08 16:38:19,672 - INFO - Train Loss: -0.0090        \n",
      "2025-12-08 16:38:19,673 - INFO - Train Log_return: -0.0133\n",
      "2025-12-08 16:38:19,673 - INFO - Train Mean_return: 0.0148\n",
      "2025-12-08 16:38:19,673 - INFO - Val   Loss: 0.0504\n",
      "2025-12-08 16:38:19,674 - INFO - Val   Log_return: 0.0371\n",
      "2025-12-08 16:38:19,674 - INFO - Val   Mean_return: -0.0314\n",
      "2025-12-08 16:38:19,674 - INFO - New best model found! Updating best state dict.\n",
      "2025-12-08 16:38:19,676 - INFO - \n",
      "2025-12-08 16:38:19,676 - INFO - Epoch 2/20\n",
      "2025-12-08 16:38:20,536 - INFO - Train Loss: -0.0131       \n",
      "2025-12-08 16:38:20,537 - INFO - Train Log_return: -0.0211\n",
      "2025-12-08 16:38:20,537 - INFO - Train Mean_return: 0.0239\n",
      "2025-12-08 16:38:20,538 - INFO - Val   Loss: 0.0427\n",
      "2025-12-08 16:38:20,539 - INFO - Val   Log_return: 0.0334\n",
      "2025-12-08 16:38:20,539 - INFO - Val   Mean_return: -0.0294\n",
      "2025-12-08 16:38:20,539 - INFO - New best model found! Updating best state dict.\n",
      "2025-12-08 16:38:20,541 - INFO - \n",
      "2025-12-08 16:38:20,541 - INFO - Epoch 3/20\n",
      "2025-12-08 16:38:21,423 - INFO - Train Loss: -0.0064        \n",
      "2025-12-08 16:38:21,424 - INFO - Train Log_return: -0.0210\n",
      "2025-12-08 16:38:21,424 - INFO - Train Mean_return: 0.0242\n",
      "2025-12-08 16:38:21,424 - INFO - Val   Loss: 0.0624\n",
      "2025-12-08 16:38:21,425 - INFO - Val   Log_return: 0.0429\n",
      "2025-12-08 16:38:21,425 - INFO - Val   Mean_return: -0.0347\n",
      "2025-12-08 16:38:21,425 - INFO - \n",
      "2025-12-08 16:38:21,425 - INFO - Epoch 4/20\n",
      "2025-12-08 16:38:22,280 - INFO - Train Loss: -0.0108       \n",
      "2025-12-08 16:38:22,280 - INFO - Train Log_return: -0.0158\n",
      "2025-12-08 16:38:22,281 - INFO - Train Mean_return: 0.0175\n",
      "2025-12-08 16:38:22,281 - INFO - Val   Loss: 0.0552\n",
      "2025-12-08 16:38:22,281 - INFO - Val   Log_return: 0.0405\n",
      "2025-12-08 16:38:22,282 - INFO - Val   Mean_return: -0.0338\n",
      "2025-12-08 16:38:22,282 - INFO - \n",
      "2025-12-08 16:38:22,282 - INFO - Epoch 5/20\n",
      "2025-12-08 16:38:23,141 - INFO - Train Loss: -0.0117       \n",
      "2025-12-08 16:38:23,141 - INFO - Train Log_return: -0.0189\n",
      "2025-12-08 16:38:23,142 - INFO - Train Mean_return: 0.0214\n",
      "2025-12-08 16:38:23,142 - INFO - Val   Loss: 0.0419\n",
      "2025-12-08 16:38:23,142 - INFO - Val   Log_return: 0.0342\n",
      "2025-12-08 16:38:23,142 - INFO - Val   Mean_return: -0.0307\n",
      "2025-12-08 16:38:23,142 - INFO - New best model found! Updating best state dict.\n",
      "2025-12-08 16:38:23,144 - INFO - \n",
      "2025-12-08 16:38:23,144 - INFO - Epoch 6/20\n",
      "2025-12-08 16:38:24,017 - INFO - Train Loss: -0.0078        \n",
      "2025-12-08 16:38:24,017 - INFO - Train Log_return: -0.0120\n",
      "2025-12-08 16:38:24,018 - INFO - Train Mean_return: 0.0135\n",
      "2025-12-08 16:38:24,018 - INFO - Val   Loss: 0.0419\n",
      "2025-12-08 16:38:24,018 - INFO - Val   Log_return: 0.0339\n",
      "2025-12-08 16:38:24,019 - INFO - Val   Mean_return: -0.0304\n",
      "2025-12-08 16:38:24,019 - INFO - New best model found! Updating best state dict.\n",
      "2025-12-08 16:38:24,020 - INFO - \n",
      "2025-12-08 16:38:24,020 - INFO - Epoch 7/20\n",
      "2025-12-08 16:38:24,874 - INFO - Train Loss: -0.0072        \n",
      "2025-12-08 16:38:24,875 - INFO - Train Log_return: -0.0108\n",
      "2025-12-08 16:38:24,875 - INFO - Train Mean_return: 0.0121\n",
      "2025-12-08 16:38:24,875 - INFO - Val   Loss: 0.0423\n",
      "2025-12-08 16:38:24,876 - INFO - Val   Log_return: 0.0343\n",
      "2025-12-08 16:38:24,876 - INFO - Val   Mean_return: -0.0307\n",
      "2025-12-08 16:38:24,876 - INFO - \n",
      "2025-12-08 16:38:24,876 - INFO - Epoch 8/20\n",
      "2025-12-08 16:38:25,756 - INFO - Train Loss: -0.0074        \n",
      "2025-12-08 16:38:25,756 - INFO - Train Log_return: -0.0110\n",
      "2025-12-08 16:38:25,757 - INFO - Train Mean_return: 0.0123\n",
      "2025-12-08 16:38:25,757 - INFO - Val   Loss: 0.0419\n",
      "2025-12-08 16:38:25,758 - INFO - Val   Log_return: 0.0337\n",
      "2025-12-08 16:38:25,758 - INFO - Val   Mean_return: -0.0301\n",
      "2025-12-08 16:38:25,758 - INFO - New best model found! Updating best state dict.\n",
      "2025-12-08 16:38:25,760 - INFO - \n",
      "2025-12-08 16:38:25,760 - INFO - Epoch 9/20\n",
      "2025-12-08 16:38:26,625 - INFO - Train Loss: -0.0077        \n",
      "2025-12-08 16:38:26,625 - INFO - Train Log_return: -0.0121\n",
      "2025-12-08 16:38:26,625 - INFO - Train Mean_return: 0.0135\n",
      "2025-12-08 16:38:26,626 - INFO - Val   Loss: 0.0417\n",
      "2025-12-08 16:38:26,626 - INFO - Val   Log_return: 0.0334\n",
      "2025-12-08 16:38:26,627 - INFO - Val   Mean_return: -0.0298\n",
      "2025-12-08 16:38:26,627 - INFO - New best model found! Updating best state dict.\n",
      "2025-12-08 16:38:26,628 - INFO - \n",
      "2025-12-08 16:38:26,629 - INFO - Epoch 10/20\n",
      "2025-12-08 16:38:27,483 - INFO - Train Loss: -0.0076        \n",
      "2025-12-08 16:38:27,483 - INFO - Train Log_return: -0.0111\n",
      "2025-12-08 16:38:27,484 - INFO - Train Mean_return: 0.0124\n",
      "2025-12-08 16:38:27,484 - INFO - Val   Loss: 0.0422\n",
      "2025-12-08 16:38:27,484 - INFO - Val   Log_return: 0.0341\n",
      "2025-12-08 16:38:27,485 - INFO - Val   Mean_return: -0.0306\n",
      "2025-12-08 16:38:27,485 - INFO - \n",
      "2025-12-08 16:38:27,485 - INFO - Epoch 11/20\n",
      "2025-12-08 16:38:28,379 - INFO - Train Loss: -0.0080        \n",
      "2025-12-08 16:38:28,380 - INFO - Train Log_return: -0.0118\n",
      "2025-12-08 16:38:28,380 - INFO - Train Mean_return: 0.0131\n",
      "2025-12-08 16:38:28,380 - INFO - Val   Loss: 0.0413\n",
      "2025-12-08 16:38:28,380 - INFO - Val   Log_return: 0.0331\n",
      "2025-12-08 16:38:28,381 - INFO - Val   Mean_return: -0.0295\n",
      "2025-12-08 16:38:28,381 - INFO - New best model found! Updating best state dict.\n",
      "2025-12-08 16:38:28,382 - INFO - \n",
      "2025-12-08 16:38:28,382 - INFO - Epoch 12/20\n",
      "2025-12-08 16:38:29,227 - INFO - Train Loss: -0.0096       \n",
      "2025-12-08 16:38:29,227 - INFO - Train Log_return: -0.0139\n",
      "2025-12-08 16:38:29,228 - INFO - Train Mean_return: 0.0154\n",
      "2025-12-08 16:38:29,228 - INFO - Val   Loss: 0.0477\n",
      "2025-12-08 16:38:29,228 - INFO - Val   Log_return: 0.0356\n",
      "2025-12-08 16:38:29,228 - INFO - Val   Mean_return: -0.0305\n",
      "2025-12-08 16:38:29,229 - INFO - \n",
      "2025-12-08 16:38:29,229 - INFO - Epoch 13/20\n",
      "2025-12-08 16:38:30,095 - INFO - Train Loss: -0.0121        \n",
      "2025-12-08 16:38:30,095 - INFO - Train Log_return: -0.0185\n",
      "2025-12-08 16:38:30,096 - INFO - Train Mean_return: 0.0208\n",
      "2025-12-08 16:38:30,096 - INFO - Val   Loss: 0.0607\n",
      "2025-12-08 16:38:30,096 - INFO - Val   Log_return: 0.0430\n",
      "2025-12-08 16:38:30,096 - INFO - Val   Mean_return: -0.0351\n",
      "2025-12-08 16:38:30,097 - INFO - \n",
      "2025-12-08 16:38:30,097 - INFO - Epoch 14/20\n",
      "2025-12-08 16:38:30,976 - INFO - Train Loss: -0.0122        \n",
      "2025-12-08 16:38:30,977 - INFO - Train Log_return: -0.0191\n",
      "2025-12-08 16:38:30,977 - INFO - Train Mean_return: 0.0215\n",
      "2025-12-08 16:38:30,977 - INFO - Val   Loss: 0.0616\n",
      "2025-12-08 16:38:30,978 - INFO - Val   Log_return: 0.0448\n",
      "2025-12-08 16:38:30,978 - INFO - Val   Mean_return: -0.0371\n",
      "2025-12-08 16:38:30,978 - INFO - \n",
      "2025-12-08 16:38:30,978 - INFO - Epoch 15/20\n",
      "2025-12-08 16:38:31,840 - INFO - Train Loss: -0.0133        \n",
      "2025-12-08 16:38:31,840 - INFO - Train Log_return: -0.0211\n",
      "2025-12-08 16:38:31,841 - INFO - Train Mean_return: 0.0239\n",
      "2025-12-08 16:38:31,841 - INFO - Val   Loss: 0.0773\n",
      "2025-12-08 16:38:31,841 - INFO - Val   Log_return: 0.0549\n",
      "2025-12-08 16:38:31,842 - INFO - Val   Mean_return: -0.0442\n",
      "2025-12-08 16:38:31,842 - INFO - \n",
      "2025-12-08 16:38:31,842 - INFO - Epoch 16/20\n",
      "2025-12-08 16:38:32,712 - INFO - Train Loss: -0.0143        \n",
      "2025-12-08 16:38:32,712 - INFO - Train Log_return: -0.0227\n",
      "2025-12-08 16:38:32,713 - INFO - Train Mean_return: 0.0257\n",
      "2025-12-08 16:38:32,713 - INFO - Val   Loss: 0.0767\n",
      "2025-12-08 16:38:32,713 - INFO - Val   Log_return: 0.0542\n",
      "2025-12-08 16:38:32,713 - INFO - Val   Mean_return: -0.0435\n",
      "2025-12-08 16:38:32,714 - INFO - \n",
      "2025-12-08 16:38:32,714 - INFO - Epoch 17/20\n",
      "2025-12-08 16:38:33,599 - INFO - Train Loss: -0.0147        \n",
      "2025-12-08 16:38:33,600 - INFO - Train Log_return: -0.0233\n",
      "2025-12-08 16:38:33,600 - INFO - Train Mean_return: 0.0264\n",
      "2025-12-08 16:38:33,600 - INFO - Val   Loss: 0.0733\n",
      "2025-12-08 16:38:33,600 - INFO - Val   Log_return: 0.0529\n",
      "2025-12-08 16:38:33,601 - INFO - Val   Mean_return: -0.0434\n",
      "2025-12-08 16:38:33,601 - INFO - \n",
      "2025-12-08 16:38:33,601 - INFO - Epoch 18/20\n",
      "2025-12-08 16:38:34,492 - INFO - Train Loss: -0.0152        \n",
      "2025-12-08 16:38:34,493 - INFO - Train Log_return: -0.0241\n",
      "2025-12-08 16:38:34,493 - INFO - Train Mean_return: 0.0272\n",
      "2025-12-08 16:38:34,493 - INFO - Val   Loss: 0.0765\n",
      "2025-12-08 16:38:34,494 - INFO - Val   Log_return: 0.0536\n",
      "2025-12-08 16:38:34,494 - INFO - Val   Mean_return: -0.0429\n",
      "2025-12-08 16:38:34,494 - INFO - \n",
      "2025-12-08 16:38:34,494 - INFO - Epoch 19/20\n",
      "2025-12-08 16:38:35,426 - INFO - Train Loss: -0.0153        \n",
      "2025-12-08 16:38:35,427 - INFO - Train Log_return: -0.0242\n",
      "2025-12-08 16:38:35,427 - INFO - Train Mean_return: 0.0274\n",
      "2025-12-08 16:38:35,427 - INFO - Val   Loss: 0.0749\n",
      "2025-12-08 16:38:35,428 - INFO - Val   Log_return: 0.0524\n",
      "2025-12-08 16:38:35,428 - INFO - Val   Mean_return: -0.0419\n",
      "2025-12-08 16:38:35,428 - INFO - \n",
      "2025-12-08 16:38:35,429 - INFO - Epoch 20/20\n",
      "2025-12-08 16:38:36,316 - INFO - Train Loss: -0.0150        \n",
      "2025-12-08 16:38:36,316 - INFO - Train Log_return: -0.0242\n",
      "2025-12-08 16:38:36,317 - INFO - Train Mean_return: 0.0274\n",
      "2025-12-08 16:38:36,317 - INFO - Val   Loss: 0.0755\n",
      "2025-12-08 16:38:36,318 - INFO - Val   Log_return: 0.0525\n",
      "2025-12-08 16:38:36,318 - INFO - Val   Mean_return: -0.0417\n",
      "2025-12-08 16:38:36,318 - INFO - \n",
      "2025-12-08 16:38:36,909 - INFO - [PolicyGradient] [VAL] Epoch 0/10 — CumulativeReturn: 0.3563, MeanReturnPercentage: 2.7700, ARR: 0.3249, AVOL: 0.3191, MDD: 16.2347, ASR: 1.0182, CR: 0.0200, DDR: 1.1347, SoR: 0.3352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PolicyGradient] [VAL] Epoch 0/10 — Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:38:37,492 - INFO - Found better val loss, updating episode_returns\n",
      "2025-12-08 16:38:37,493 - INFO - Len of episode_returns: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for 1970-01-02 00:00:00-05:00 to 2011-01-01 00:00:00+00:00 with train set last date 2009-01-01 00:00:00+00:00 and val set last date 2010-01-01 00:00:00+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:38:38,369 - WARNING - No data found for ek_us_d.csv in root folder\n",
      "2025-12-08 16:38:40,842 - INFO - retrieved 28 assets\n",
      "2025-12-08 16:38:40,843 - INFO - Using monolithic slices with -60 timestamps\n",
      "2025-12-08 16:38:41,507 - INFO - Found 9842 train slices, 336 val slices, 335 test slices\n",
      "2025-12-08 16:38:41,508 - INFO - Trained per-asset targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14125, 28, 60, 16) (14125, 28) (14125, 28) (14125, 28) (14125, 28) (366, 28, 60, 16) (366, 28) (366, 28) (366, 28) (366, 28)\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:38:54,219 - INFO - Model compiled with torch.compile()\n",
      "2025-12-08 16:38:54,220 - INFO - Epoch 1/20\n",
      "2025-12-08 16:38:56,198 - INFO - Train Loss: -0.0058        \n",
      "2025-12-08 16:38:56,199 - INFO - Train Log_return: -0.0093\n",
      "2025-12-08 16:38:56,199 - INFO - Train Mean_return: 0.0105\n",
      "2025-12-08 16:38:56,200 - INFO - Val   Loss: -0.0134\n",
      "2025-12-08 16:38:56,200 - INFO - Val   Log_return: -0.0270\n",
      "2025-12-08 16:38:56,200 - INFO - Val   Mean_return: 0.0319\n",
      "2025-12-08 16:38:56,201 - INFO - New best model found! Updating best state dict.\n",
      "2025-12-08 16:38:56,202 - INFO - \n",
      "2025-12-08 16:38:56,203 - INFO - Epoch 2/20\n",
      "2025-12-08 16:38:57,119 - INFO - Train Loss: -0.0062        \n",
      "2025-12-08 16:38:57,120 - INFO - Train Log_return: -0.0099\n",
      "2025-12-08 16:38:57,120 - INFO - Train Mean_return: 0.0112\n",
      "2025-12-08 16:38:57,120 - INFO - Val   Loss: -0.0127\n",
      "2025-12-08 16:38:57,121 - INFO - Val   Log_return: -0.0262\n",
      "2025-12-08 16:38:57,121 - INFO - Val   Mean_return: 0.0309\n",
      "2025-12-08 16:38:57,121 - INFO - \n",
      "2025-12-08 16:38:57,121 - INFO - Epoch 3/20\n",
      "2025-12-08 16:38:58,025 - INFO - Train Loss: -0.0070        \n",
      "2025-12-08 16:38:58,025 - INFO - Train Log_return: -0.0108\n",
      "2025-12-08 16:38:58,025 - INFO - Train Mean_return: 0.0122\n",
      "2025-12-08 16:38:58,025 - INFO - Val   Loss: -0.0119\n",
      "2025-12-08 16:38:58,026 - INFO - Val   Log_return: -0.0291\n",
      "2025-12-08 16:38:58,026 - INFO - Val   Mean_return: 0.0350\n",
      "2025-12-08 16:38:58,026 - INFO - \n",
      "2025-12-08 16:38:58,026 - INFO - Epoch 4/20\n",
      "2025-12-08 16:38:58,927 - INFO - Train Loss: -0.0093        \n",
      "2025-12-08 16:38:58,928 - INFO - Train Log_return: -0.0158\n",
      "2025-12-08 16:38:58,928 - INFO - Train Mean_return: 0.0180\n",
      "2025-12-08 16:38:58,928 - INFO - Val   Loss: -0.0008\n",
      "2025-12-08 16:38:58,929 - INFO - Val   Log_return: -0.0260\n",
      "2025-12-08 16:38:58,929 - INFO - Val   Mean_return: 0.0342\n",
      "2025-12-08 16:38:58,929 - INFO - \n",
      "2025-12-08 16:38:58,929 - INFO - Epoch 5/20\n",
      "2025-12-08 16:38:59,842 - INFO - Train Loss: -0.0069        \n",
      "2025-12-08 16:38:59,842 - INFO - Train Log_return: -0.0115\n",
      "2025-12-08 16:38:59,843 - INFO - Train Mean_return: 0.0131\n",
      "2025-12-08 16:38:59,843 - INFO - Val   Loss: -0.0130\n",
      "2025-12-08 16:38:59,843 - INFO - Val   Log_return: -0.0279\n",
      "2025-12-08 16:38:59,843 - INFO - Val   Mean_return: 0.0333\n",
      "2025-12-08 16:38:59,844 - INFO - \n",
      "2025-12-08 16:38:59,844 - INFO - Epoch 6/20\n",
      "2025-12-08 16:39:00,758 - INFO - Train Loss: -0.0103        \n",
      "2025-12-08 16:39:00,758 - INFO - Train Log_return: -0.0174\n",
      "2025-12-08 16:39:00,759 - INFO - Train Mean_return: 0.0199\n",
      "2025-12-08 16:39:00,759 - INFO - Val   Loss: -0.0025\n",
      "2025-12-08 16:39:00,759 - INFO - Val   Log_return: -0.0272\n",
      "2025-12-08 16:39:00,760 - INFO - Val   Mean_return: 0.0353\n",
      "2025-12-08 16:39:00,760 - INFO - \n",
      "2025-12-08 16:39:00,760 - INFO - Epoch 7/20\n",
      "2025-12-08 16:39:01,669 - INFO - Train Loss: -0.0109        \n",
      "2025-12-08 16:39:01,669 - INFO - Train Log_return: -0.0185\n",
      "2025-12-08 16:39:01,670 - INFO - Train Mean_return: 0.0211\n",
      "2025-12-08 16:39:01,670 - INFO - Val   Loss: -0.0013\n",
      "2025-12-08 16:39:01,670 - INFO - Val   Log_return: -0.0266\n",
      "2025-12-08 16:39:01,671 - INFO - Val   Mean_return: 0.0350\n",
      "2025-12-08 16:39:01,671 - INFO - \n",
      "2025-12-08 16:39:01,671 - INFO - Epoch 8/20\n",
      "2025-12-08 16:39:02,566 - INFO - Train Loss: -0.0110        \n",
      "2025-12-08 16:39:02,566 - INFO - Train Log_return: -0.0193\n",
      "2025-12-08 16:39:02,566 - INFO - Train Mean_return: 0.0222\n",
      "2025-12-08 16:39:02,567 - INFO - Val   Loss: 0.0027\n",
      "2025-12-08 16:39:02,567 - INFO - Val   Log_return: -0.0299\n",
      "2025-12-08 16:39:02,567 - INFO - Val   Mean_return: 0.0408\n",
      "2025-12-08 16:39:02,567 - INFO - \n",
      "2025-12-08 16:39:02,568 - INFO - Epoch 9/20\n",
      "2025-12-08 16:39:03,482 - INFO - Train Loss: -0.0105        \n",
      "2025-12-08 16:39:03,483 - INFO - Train Log_return: -0.0180\n",
      "2025-12-08 16:39:03,483 - INFO - Train Mean_return: 0.0207\n",
      "2025-12-08 16:39:03,483 - INFO - Val   Loss: 0.0196\n",
      "2025-12-08 16:39:03,483 - INFO - Val   Log_return: -0.0124\n",
      "2025-12-08 16:39:03,484 - INFO - Val   Mean_return: 0.0231\n",
      "2025-12-08 16:39:03,484 - INFO - \n",
      "2025-12-08 16:39:03,484 - INFO - Epoch 10/20\n",
      "2025-12-08 16:39:04,376 - INFO - Train Loss: -0.0083        \n",
      "2025-12-08 16:39:04,376 - INFO - Train Log_return: -0.0169\n",
      "2025-12-08 16:39:04,377 - INFO - Train Mean_return: 0.0196\n",
      "2025-12-08 16:39:04,377 - INFO - Val   Loss: -0.0116\n",
      "2025-12-08 16:39:04,377 - INFO - Val   Log_return: -0.0258\n",
      "2025-12-08 16:39:04,378 - INFO - Val   Mean_return: 0.0308\n",
      "2025-12-08 16:39:04,378 - INFO - \n",
      "2025-12-08 16:39:04,378 - INFO - Epoch 11/20\n",
      "2025-12-08 16:39:05,295 - INFO - Train Loss: -0.0094        \n",
      "2025-12-08 16:39:05,295 - INFO - Train Log_return: -0.0164\n",
      "2025-12-08 16:39:05,295 - INFO - Train Mean_return: 0.0188\n",
      "2025-12-08 16:39:05,295 - INFO - Val   Loss: -0.0026\n",
      "2025-12-08 16:39:05,296 - INFO - Val   Log_return: -0.0242\n",
      "2025-12-08 16:39:05,296 - INFO - Val   Mean_return: 0.0314\n",
      "2025-12-08 16:39:05,296 - INFO - Early stopping triggered at epoch 11\n",
      "2025-12-08 16:39:05,892 - INFO - [PolicyGradient] [VAL] Epoch 0/10 — CumulativeReturn: 0.1283, MeanReturnPercentage: 1.0427, ARR: 0.1178, AVOL: 0.1685, MDD: 11.9329, ASR: 0.6992, CR: 0.0099, DDR: 1.1573, SoR: 0.3547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PolicyGradient] [VAL] Epoch 0/10 — Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:39:06,339 - INFO - Found better val loss, updating episode_returns\n",
      "2025-12-08 16:39:06,339 - INFO - Len of episode_returns: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for 1970-01-02 00:00:00-05:00 to 2012-01-01 00:00:00+00:00 with train set last date 2010-01-01 00:00:00+00:00 and val set last date 2011-01-01 00:00:00+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:39:07,223 - WARNING - No data found for ek_us_d.csv in root folder\n",
      "2025-12-08 16:39:09,542 - INFO - retrieved 28 assets\n",
      "2025-12-08 16:39:09,542 - INFO - Using monolithic slices with -60 timestamps\n",
      "2025-12-08 16:39:10,435 - INFO - Found 10094 train slices, 335 val slices, 335 test slices\n",
      "2025-12-08 16:39:10,436 - INFO - Trained per-asset targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14490, 28, 60, 16) (14490, 28) (14490, 28) (14490, 28) (14490, 28) (365, 28, 60, 16) (365, 28) (365, 28) (365, 28) (365, 28)\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:39:23,131 - INFO - Model compiled with torch.compile()\n",
      "2025-12-08 16:39:23,132 - INFO - Epoch 1/20\n",
      "2025-12-08 16:39:24,897 - INFO - Train Loss: -0.0059        \n",
      "2025-12-08 16:39:24,898 - INFO - Train Log_return: -0.0096\n",
      "2025-12-08 16:39:24,898 - INFO - Train Mean_return: 0.0110\n",
      "2025-12-08 16:39:24,898 - INFO - Val   Loss: -0.0042\n",
      "2025-12-08 16:39:24,899 - INFO - Val   Log_return: -0.0073\n",
      "2025-12-08 16:39:24,899 - INFO - Val   Mean_return: 0.0084\n",
      "2025-12-08 16:39:24,899 - INFO - New best model found! Updating best state dict.\n",
      "2025-12-08 16:39:24,901 - INFO - \n",
      "2025-12-08 16:39:24,901 - INFO - Epoch 2/20\n",
      "2025-12-08 16:39:25,859 - INFO - Train Loss: -0.0064        \n",
      "2025-12-08 16:39:25,860 - INFO - Train Log_return: -0.0103\n",
      "2025-12-08 16:39:25,860 - INFO - Train Mean_return: 0.0116\n",
      "2025-12-08 16:39:25,860 - INFO - Val   Loss: -0.0075\n",
      "2025-12-08 16:39:25,861 - INFO - Val   Log_return: -0.0105\n",
      "2025-12-08 16:39:25,861 - INFO - Val   Mean_return: 0.0115\n",
      "2025-12-08 16:39:25,861 - INFO - New best model found! Updating best state dict.\n",
      "2025-12-08 16:39:25,862 - INFO - \n",
      "2025-12-08 16:39:25,863 - INFO - Epoch 3/20\n",
      "2025-12-08 16:39:26,812 - INFO - Train Loss: -0.0094        \n",
      "2025-12-08 16:39:26,812 - INFO - Train Log_return: -0.0155\n",
      "2025-12-08 16:39:26,812 - INFO - Train Mean_return: 0.0176\n",
      "2025-12-08 16:39:26,812 - INFO - Val   Loss: -0.0062\n",
      "2025-12-08 16:39:26,813 - INFO - Val   Log_return: -0.0094\n",
      "2025-12-08 16:39:26,813 - INFO - Val   Mean_return: 0.0105\n",
      "2025-12-08 16:39:26,813 - INFO - \n",
      "2025-12-08 16:39:26,814 - INFO - Epoch 4/20\n",
      "2025-12-08 16:39:27,727 - INFO - Train Loss: -0.0107        \n",
      "2025-12-08 16:39:27,727 - INFO - Train Log_return: -0.0185\n",
      "2025-12-08 16:39:27,727 - INFO - Train Mean_return: 0.0212\n",
      "2025-12-08 16:39:27,728 - INFO - Val   Loss: -0.0066\n",
      "2025-12-08 16:39:27,728 - INFO - Val   Log_return: -0.0101\n",
      "2025-12-08 16:39:27,728 - INFO - Val   Mean_return: 0.0113\n",
      "2025-12-08 16:39:27,728 - INFO - \n",
      "2025-12-08 16:39:27,729 - INFO - Epoch 5/20\n",
      "2025-12-08 16:39:28,647 - INFO - Train Loss: -0.0060        \n",
      "2025-12-08 16:39:28,647 - INFO - Train Log_return: -0.0104\n",
      "2025-12-08 16:39:28,648 - INFO - Train Mean_return: 0.0119\n",
      "2025-12-08 16:39:28,648 - INFO - Val   Loss: -0.0044\n",
      "2025-12-08 16:39:28,648 - INFO - Val   Log_return: -0.0076\n",
      "2025-12-08 16:39:28,648 - INFO - Val   Mean_return: 0.0086\n",
      "2025-12-08 16:39:28,648 - INFO - \n",
      "2025-12-08 16:39:28,649 - INFO - Epoch 6/20\n",
      "2025-12-08 16:39:29,600 - INFO - Train Loss: -0.0058        \n",
      "2025-12-08 16:39:29,600 - INFO - Train Log_return: -0.0096\n",
      "2025-12-08 16:39:29,600 - INFO - Train Mean_return: 0.0110\n",
      "2025-12-08 16:39:29,601 - INFO - Val   Loss: -0.0044\n",
      "2025-12-08 16:39:29,601 - INFO - Val   Log_return: -0.0075\n",
      "2025-12-08 16:39:29,601 - INFO - Val   Mean_return: 0.0086\n",
      "2025-12-08 16:39:29,602 - INFO - \n",
      "2025-12-08 16:39:29,602 - INFO - Epoch 7/20\n",
      "2025-12-08 16:39:30,557 - INFO - Train Loss: -0.0059        \n",
      "2025-12-08 16:39:30,558 - INFO - Train Log_return: -0.0097\n",
      "2025-12-08 16:39:30,558 - INFO - Train Mean_return: 0.0110\n",
      "2025-12-08 16:39:30,558 - INFO - Val   Loss: -0.0046\n",
      "2025-12-08 16:39:30,559 - INFO - Val   Log_return: -0.0077\n",
      "2025-12-08 16:39:30,559 - INFO - Val   Mean_return: 0.0087\n",
      "2025-12-08 16:39:30,559 - INFO - \n",
      "2025-12-08 16:39:30,559 - INFO - Epoch 8/20\n",
      "2025-12-08 16:39:31,504 - INFO - Train Loss: -0.0060        \n",
      "2025-12-08 16:39:31,505 - INFO - Train Log_return: -0.0097\n",
      "2025-12-08 16:39:31,505 - INFO - Train Mean_return: 0.0110\n",
      "2025-12-08 16:39:31,505 - INFO - Val   Loss: -0.0047\n",
      "2025-12-08 16:39:31,506 - INFO - Val   Log_return: -0.0078\n",
      "2025-12-08 16:39:31,506 - INFO - Val   Mean_return: 0.0088\n",
      "2025-12-08 16:39:31,506 - INFO - \n",
      "2025-12-08 16:39:31,506 - INFO - Epoch 9/20\n",
      "2025-12-08 16:39:32,444 - INFO - Train Loss: -0.0060        \n",
      "2025-12-08 16:39:32,445 - INFO - Train Log_return: -0.0097\n",
      "2025-12-08 16:39:32,445 - INFO - Train Mean_return: 0.0110\n",
      "2025-12-08 16:39:32,445 - INFO - Val   Loss: -0.0043\n",
      "2025-12-08 16:39:32,446 - INFO - Val   Log_return: -0.0074\n",
      "2025-12-08 16:39:32,446 - INFO - Val   Mean_return: 0.0085\n",
      "2025-12-08 16:39:32,446 - INFO - \n",
      "2025-12-08 16:39:32,447 - INFO - Epoch 10/20\n",
      "2025-12-08 16:39:33,376 - INFO - Train Loss: -0.0062        \n",
      "2025-12-08 16:39:33,377 - INFO - Train Log_return: -0.0100\n",
      "2025-12-08 16:39:33,377 - INFO - Train Mean_return: 0.0114\n",
      "2025-12-08 16:39:33,377 - INFO - Val   Loss: -0.0046\n",
      "2025-12-08 16:39:33,377 - INFO - Val   Log_return: -0.0077\n",
      "2025-12-08 16:39:33,378 - INFO - Val   Mean_return: 0.0088\n",
      "2025-12-08 16:39:33,378 - INFO - \n",
      "2025-12-08 16:39:33,378 - INFO - Epoch 11/20\n",
      "2025-12-08 16:39:34,295 - INFO - Train Loss: -0.0062        \n",
      "2025-12-08 16:39:34,296 - INFO - Train Log_return: -0.0100\n",
      "2025-12-08 16:39:34,296 - INFO - Train Mean_return: 0.0114\n",
      "2025-12-08 16:39:34,296 - INFO - Val   Loss: -0.0053\n",
      "2025-12-08 16:39:34,297 - INFO - Val   Log_return: -0.0083\n",
      "2025-12-08 16:39:34,297 - INFO - Val   Mean_return: 0.0094\n",
      "2025-12-08 16:39:34,297 - INFO - \n",
      "2025-12-08 16:39:34,297 - INFO - Epoch 12/20\n",
      "2025-12-08 16:39:35,259 - INFO - Train Loss: -0.0062        \n",
      "2025-12-08 16:39:35,259 - INFO - Train Log_return: -0.0102\n",
      "2025-12-08 16:39:35,259 - INFO - Train Mean_return: 0.0115\n",
      "2025-12-08 16:39:35,260 - INFO - Val   Loss: -0.0045\n",
      "2025-12-08 16:39:35,260 - INFO - Val   Log_return: -0.0076\n",
      "2025-12-08 16:39:35,260 - INFO - Val   Mean_return: 0.0087\n",
      "2025-12-08 16:39:35,261 - INFO - Early stopping triggered at epoch 12\n",
      "2025-12-08 16:39:35,754 - INFO - [PolicyGradient] [VAL] Epoch 0/10 — CumulativeReturn: -0.0034, MeanReturnPercentage: 0.1476, ARR: -0.0031, AVOL: 0.2148, MDD: 15.9327, ASR: -0.0144, CR: -0.0002, DDR: -0.0253, SoR: 0.0417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PolicyGradient] [VAL] Epoch 0/10 — Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:39:36,271 - INFO - Found better val loss, updating episode_returns\n",
      "2025-12-08 16:39:36,272 - INFO - Len of episode_returns: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for 1970-01-02 00:00:00-05:00 to 2013-01-01 00:00:00+00:00 with train set last date 2011-01-01 00:00:00+00:00 and val set last date 2012-01-01 00:00:00+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:39:37,148 - WARNING - No data found for ek_us_d.csv in root folder\n",
      "2025-12-08 16:39:39,601 - INFO - retrieved 28 assets\n",
      "2025-12-08 16:39:39,602 - INFO - Using monolithic slices with -60 timestamps\n",
      "2025-12-08 16:39:40,295 - INFO - Found 10346 train slices, 335 val slices, 332 test slices\n",
      "2025-12-08 16:39:40,296 - INFO - Trained per-asset targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14855, 28, 60, 16) (14855, 28) (14855, 28) (14855, 28) (14855, 28) (364, 28, 60, 16) (364, 28) (364, 28) (364, 28) (364, 28)\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:39:53,206 - INFO - Model compiled with torch.compile()\n",
      "2025-12-08 16:39:53,207 - INFO - Epoch 1/20\n",
      "2025-12-08 16:39:55,158 - INFO - Train Loss: -0.0059        \n",
      "2025-12-08 16:39:55,158 - INFO - Train Log_return: -0.0097\n",
      "2025-12-08 16:39:55,159 - INFO - Train Mean_return: 0.0110\n",
      "2025-12-08 16:39:55,159 - INFO - Val   Loss: 0.0081\n",
      "2025-12-08 16:39:55,159 - INFO - Val   Log_return: 0.0035\n",
      "2025-12-08 16:39:55,160 - INFO - Val   Mean_return: -0.0019\n",
      "2025-12-08 16:39:55,160 - INFO - New best model found! Updating best state dict.\n",
      "2025-12-08 16:39:55,162 - INFO - \n",
      "2025-12-08 16:39:55,162 - INFO - Epoch 2/20\n",
      "2025-12-08 16:39:56,197 - INFO - Train Loss: -0.0061        \n",
      "2025-12-08 16:39:56,198 - INFO - Train Log_return: -0.0101\n",
      "2025-12-08 16:39:56,198 - INFO - Train Mean_return: 0.0115\n",
      "2025-12-08 16:39:56,198 - INFO - Val   Loss: 0.0078\n",
      "2025-12-08 16:39:56,199 - INFO - Val   Log_return: 0.0033\n",
      "2025-12-08 16:39:56,199 - INFO - Val   Mean_return: -0.0017\n",
      "2025-12-08 16:39:56,199 - INFO - New best model found! Updating best state dict.\n",
      "2025-12-08 16:39:56,201 - INFO - \n",
      "2025-12-08 16:39:56,201 - INFO - Epoch 3/20\n",
      "2025-12-08 16:39:57,182 - INFO - Train Loss: -0.0060        \n",
      "2025-12-08 16:39:57,183 - INFO - Train Log_return: -0.0099\n",
      "2025-12-08 16:39:57,183 - INFO - Train Mean_return: 0.0112\n",
      "2025-12-08 16:39:57,183 - INFO - Val   Loss: 0.0088\n",
      "2025-12-08 16:39:57,183 - INFO - Val   Log_return: 0.0040\n",
      "2025-12-08 16:39:57,184 - INFO - Val   Mean_return: -0.0023\n",
      "2025-12-08 16:39:57,184 - INFO - \n",
      "2025-12-08 16:39:57,184 - INFO - Epoch 4/20\n",
      "2025-12-08 16:39:58,153 - INFO - Train Loss: -0.0060        \n",
      "2025-12-08 16:39:58,153 - INFO - Train Log_return: -0.0098\n",
      "2025-12-08 16:39:58,153 - INFO - Train Mean_return: 0.0112\n",
      "2025-12-08 16:39:58,154 - INFO - Val   Loss: 0.0104\n",
      "2025-12-08 16:39:58,154 - INFO - Val   Log_return: 0.0054\n",
      "2025-12-08 16:39:58,154 - INFO - Val   Mean_return: -0.0037\n",
      "2025-12-08 16:39:58,154 - INFO - \n",
      "2025-12-08 16:39:58,155 - INFO - Epoch 5/20\n",
      "2025-12-08 16:39:59,107 - INFO - Train Loss: -0.0072        \n",
      "2025-12-08 16:39:59,107 - INFO - Train Log_return: -0.0114\n",
      "2025-12-08 16:39:59,108 - INFO - Train Mean_return: 0.0129\n",
      "2025-12-08 16:39:59,108 - INFO - Val   Loss: 0.0083\n",
      "2025-12-08 16:39:59,108 - INFO - Val   Log_return: 0.0037\n",
      "2025-12-08 16:39:59,109 - INFO - Val   Mean_return: -0.0020\n",
      "2025-12-08 16:39:59,109 - INFO - \n",
      "2025-12-08 16:39:59,109 - INFO - Epoch 6/20\n",
      "2025-12-08 16:40:00,110 - INFO - Train Loss: -0.0072        \n",
      "2025-12-08 16:40:00,111 - INFO - Train Log_return: -0.0113\n",
      "2025-12-08 16:40:00,111 - INFO - Train Mean_return: 0.0127\n",
      "2025-12-08 16:40:00,111 - INFO - Val   Loss: 0.0117\n",
      "2025-12-08 16:40:00,112 - INFO - Val   Log_return: 0.0055\n",
      "2025-12-08 16:40:00,112 - INFO - Val   Mean_return: -0.0034\n",
      "2025-12-08 16:40:00,112 - INFO - \n",
      "2025-12-08 16:40:00,112 - INFO - Epoch 7/20\n",
      "2025-12-08 16:40:01,074 - INFO - Train Loss: -0.0070        \n",
      "2025-12-08 16:40:01,074 - INFO - Train Log_return: -0.0112\n",
      "2025-12-08 16:40:01,074 - INFO - Train Mean_return: 0.0127\n",
      "2025-12-08 16:40:01,075 - INFO - Val   Loss: 0.0094\n",
      "2025-12-08 16:40:01,075 - INFO - Val   Log_return: 0.0043\n",
      "2025-12-08 16:40:01,075 - INFO - Val   Mean_return: -0.0025\n",
      "2025-12-08 16:40:01,075 - INFO - \n",
      "2025-12-08 16:40:01,076 - INFO - Epoch 8/20\n",
      "2025-12-08 16:40:02,016 - INFO - Train Loss: -0.0102        \n",
      "2025-12-08 16:40:02,016 - INFO - Train Log_return: -0.0174\n",
      "2025-12-08 16:40:02,016 - INFO - Train Mean_return: 0.0198\n",
      "2025-12-08 16:40:02,016 - INFO - Val   Loss: 0.0085\n",
      "2025-12-08 16:40:02,017 - INFO - Val   Log_return: 0.0032\n",
      "2025-12-08 16:40:02,017 - INFO - Val   Mean_return: -0.0015\n",
      "2025-12-08 16:40:02,017 - INFO - \n",
      "2025-12-08 16:40:02,017 - INFO - Epoch 9/20\n",
      "2025-12-08 16:40:02,973 - INFO - Train Loss: -0.0115        \n",
      "2025-12-08 16:40:02,974 - INFO - Train Log_return: -0.0196\n",
      "2025-12-08 16:40:02,974 - INFO - Train Mean_return: 0.0224\n",
      "2025-12-08 16:40:02,974 - INFO - Val   Loss: 0.0070\n",
      "2025-12-08 16:40:02,974 - INFO - Val   Log_return: 0.0016\n",
      "2025-12-08 16:40:02,975 - INFO - Val   Mean_return: 0.0002\n",
      "2025-12-08 16:40:02,975 - INFO - New best model found! Updating best state dict.\n",
      "2025-12-08 16:40:02,976 - INFO - \n",
      "2025-12-08 16:40:02,977 - INFO - Epoch 10/20\n",
      "2025-12-08 16:40:03,929 - INFO - Train Loss: -0.0101        \n",
      "2025-12-08 16:40:03,930 - INFO - Train Log_return: -0.0178\n",
      "2025-12-08 16:40:03,930 - INFO - Train Mean_return: 0.0204\n",
      "2025-12-08 16:40:03,930 - INFO - Val   Loss: 0.0077\n",
      "2025-12-08 16:40:03,930 - INFO - Val   Log_return: 0.0031\n",
      "2025-12-08 16:40:03,931 - INFO - Val   Mean_return: -0.0015\n",
      "2025-12-08 16:40:03,931 - INFO - \n",
      "2025-12-08 16:40:03,931 - INFO - Epoch 11/20\n",
      "2025-12-08 16:40:04,903 - INFO - Train Loss: -0.0060        \n",
      "2025-12-08 16:40:04,903 - INFO - Train Log_return: -0.0100\n",
      "2025-12-08 16:40:04,903 - INFO - Train Mean_return: 0.0114\n",
      "2025-12-08 16:40:04,904 - INFO - Val   Loss: 0.0082\n",
      "2025-12-08 16:40:04,904 - INFO - Val   Log_return: 0.0036\n",
      "2025-12-08 16:40:04,904 - INFO - Val   Mean_return: -0.0020\n",
      "2025-12-08 16:40:04,904 - INFO - \n",
      "2025-12-08 16:40:04,904 - INFO - Epoch 12/20\n",
      "2025-12-08 16:40:05,973 - INFO - Train Loss: -0.0058        \n",
      "2025-12-08 16:40:05,973 - INFO - Train Log_return: -0.0096\n",
      "2025-12-08 16:40:05,974 - INFO - Train Mean_return: 0.0109\n",
      "2025-12-08 16:40:05,974 - INFO - Val   Loss: 0.0079\n",
      "2025-12-08 16:40:05,974 - INFO - Val   Log_return: 0.0033\n",
      "2025-12-08 16:40:05,974 - INFO - Val   Mean_return: -0.0017\n",
      "2025-12-08 16:40:05,975 - INFO - \n",
      "2025-12-08 16:40:05,975 - INFO - Epoch 13/20\n",
      "2025-12-08 16:40:06,932 - INFO - Train Loss: -0.0055        \n",
      "2025-12-08 16:40:06,933 - INFO - Train Log_return: -0.0092\n",
      "2025-12-08 16:40:06,933 - INFO - Train Mean_return: 0.0105\n",
      "2025-12-08 16:40:06,933 - INFO - Val   Loss: 0.0076\n",
      "2025-12-08 16:40:06,934 - INFO - Val   Log_return: 0.0031\n",
      "2025-12-08 16:40:06,934 - INFO - Val   Mean_return: -0.0015\n",
      "2025-12-08 16:40:06,934 - INFO - \n",
      "2025-12-08 16:40:06,934 - INFO - Epoch 14/20\n",
      "2025-12-08 16:40:07,887 - INFO - Train Loss: -0.0061        \n",
      "2025-12-08 16:40:07,887 - INFO - Train Log_return: -0.0098\n",
      "2025-12-08 16:40:07,887 - INFO - Train Mean_return: 0.0111\n",
      "2025-12-08 16:40:07,888 - INFO - Val   Loss: 0.0081\n",
      "2025-12-08 16:40:07,888 - INFO - Val   Log_return: 0.0034\n",
      "2025-12-08 16:40:07,888 - INFO - Val   Mean_return: -0.0019\n",
      "2025-12-08 16:40:07,888 - INFO - \n",
      "2025-12-08 16:40:07,889 - INFO - Epoch 15/20\n",
      "2025-12-08 16:40:09,116 - INFO - Train Loss: -0.0060        \n",
      "2025-12-08 16:40:09,117 - INFO - Train Log_return: -0.0097\n",
      "2025-12-08 16:40:09,117 - INFO - Train Mean_return: 0.0110\n",
      "2025-12-08 16:40:09,117 - INFO - Val   Loss: 0.0079\n",
      "2025-12-08 16:40:09,118 - INFO - Val   Log_return: 0.0033\n",
      "2025-12-08 16:40:09,118 - INFO - Val   Mean_return: -0.0018\n",
      "2025-12-08 16:40:09,118 - INFO - \n",
      "2025-12-08 16:40:09,118 - INFO - Epoch 16/20\n",
      "2025-12-08 16:40:10,066 - INFO - Train Loss: -0.0061        \n",
      "2025-12-08 16:40:10,067 - INFO - Train Log_return: -0.0098\n",
      "2025-12-08 16:40:10,067 - INFO - Train Mean_return: 0.0111\n",
      "2025-12-08 16:40:10,067 - INFO - Val   Loss: 0.0080\n",
      "2025-12-08 16:40:10,067 - INFO - Val   Log_return: 0.0034\n",
      "2025-12-08 16:40:10,068 - INFO - Val   Mean_return: -0.0018\n",
      "2025-12-08 16:40:10,068 - INFO - \n",
      "2025-12-08 16:40:10,068 - INFO - Epoch 17/20\n",
      "2025-12-08 16:40:11,059 - INFO - Train Loss: -0.0062        \n",
      "2025-12-08 16:40:11,060 - INFO - Train Log_return: -0.0100\n",
      "2025-12-08 16:40:11,060 - INFO - Train Mean_return: 0.0114\n",
      "2025-12-08 16:40:11,060 - INFO - Val   Loss: 0.0082\n",
      "2025-12-08 16:40:11,061 - INFO - Val   Log_return: 0.0036\n",
      "2025-12-08 16:40:11,061 - INFO - Val   Mean_return: -0.0020\n",
      "2025-12-08 16:40:11,061 - INFO - \n",
      "2025-12-08 16:40:11,061 - INFO - Epoch 18/20\n",
      "2025-12-08 16:40:12,017 - INFO - Train Loss: -0.0057        \n",
      "2025-12-08 16:40:12,018 - INFO - Train Log_return: -0.0094\n",
      "2025-12-08 16:40:12,018 - INFO - Train Mean_return: 0.0107\n",
      "2025-12-08 16:40:12,018 - INFO - Val   Loss: 0.0083\n",
      "2025-12-08 16:40:12,018 - INFO - Val   Log_return: 0.0038\n",
      "2025-12-08 16:40:12,019 - INFO - Val   Mean_return: -0.0022\n",
      "2025-12-08 16:40:12,019 - INFO - \n",
      "2025-12-08 16:40:12,019 - INFO - Epoch 19/20\n",
      "2025-12-08 16:40:12,998 - INFO - Train Loss: -0.0059        \n",
      "2025-12-08 16:40:12,999 - INFO - Train Log_return: -0.0096\n",
      "2025-12-08 16:40:12,999 - INFO - Train Mean_return: 0.0109\n",
      "2025-12-08 16:40:12,999 - INFO - Val   Loss: 0.0078\n",
      "2025-12-08 16:40:12,999 - INFO - Val   Log_return: 0.0033\n",
      "2025-12-08 16:40:13,000 - INFO - Val   Mean_return: -0.0017\n",
      "2025-12-08 16:40:13,000 - INFO - Early stopping triggered at epoch 19\n",
      "2025-12-08 16:40:13,494 - INFO - [PolicyGradient] [VAL] Epoch 0/10 — CumulativeReturn: -0.0165, MeanReturnPercentage: -0.0172, ARR: -0.0152, AVOL: 0.1652, MDD: 13.0104, ASR: -0.0921, CR: -0.0012, DDR: -0.0781, SoR: -0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PolicyGradient] [VAL] Epoch 0/10 — Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:40:14,059 - INFO - Found better val loss, updating episode_returns\n",
      "2025-12-08 16:40:14,060 - INFO - Len of episode_returns: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for 1970-01-02 00:00:00-05:00 to 2014-01-01 00:00:00+00:00 with train set last date 2012-01-01 00:00:00+00:00 and val set last date 2013-01-01 00:00:00+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:40:14,887 - WARNING - No data found for ek_us_d.csv in root folder\n",
      "2025-12-08 16:40:17,115 - INFO - retrieved 28 assets\n",
      "2025-12-08 16:40:17,116 - INFO - Using monolithic slices with -60 timestamps\n",
      "2025-12-08 16:40:18,013 - INFO - Found 10598 train slices, 332 val slices, 333 test slices\n",
      "2025-12-08 16:40:18,014 - INFO - Trained per-asset targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15219, 28, 60, 16) (15219, 28) (15219, 28) (15219, 28) (15219, 28) (365, 28, 60, 16) (365, 28) (365, 28) (365, 28) (365, 28)\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:40:29,166 - INFO - Model compiled with torch.compile()\n",
      "2025-12-08 16:40:29,167 - INFO - Epoch 1/20\n",
      "2025-12-08 16:40:31,116 - INFO - Train Loss: -0.0056        \n",
      "2025-12-08 16:40:31,117 - INFO - Train Log_return: -0.0093\n",
      "2025-12-08 16:40:31,117 - INFO - Train Mean_return: 0.0107\n",
      "2025-12-08 16:40:31,117 - INFO - Val   Loss: -0.0040\n",
      "2025-12-08 16:40:31,118 - INFO - Val   Log_return: -0.0053\n",
      "2025-12-08 16:40:31,118 - INFO - Val   Mean_return: 0.0058\n",
      "2025-12-08 16:40:31,118 - INFO - New best model found! Updating best state dict.\n",
      "2025-12-08 16:40:31,120 - INFO - \n",
      "2025-12-08 16:40:31,120 - INFO - Epoch 2/20\n",
      "2025-12-08 16:40:32,084 - INFO - Train Loss: -0.0064        \n",
      "2025-12-08 16:40:32,085 - INFO - Train Log_return: -0.0102\n",
      "2025-12-08 16:40:32,085 - INFO - Train Mean_return: 0.0115\n",
      "2025-12-08 16:40:32,085 - INFO - Val   Loss: -0.0024\n",
      "2025-12-08 16:40:32,086 - INFO - Val   Log_return: -0.0040\n",
      "2025-12-08 16:40:32,086 - INFO - Val   Mean_return: 0.0046\n",
      "2025-12-08 16:40:32,086 - INFO - \n",
      "2025-12-08 16:40:32,086 - INFO - Epoch 3/20\n",
      "2025-12-08 16:40:33,052 - INFO - Train Loss: -0.0088        \n",
      "2025-12-08 16:40:33,052 - INFO - Train Log_return: -0.0152\n",
      "2025-12-08 16:40:33,053 - INFO - Train Mean_return: 0.0175\n",
      "2025-12-08 16:40:33,053 - INFO - Val   Loss: -0.0031\n",
      "2025-12-08 16:40:33,053 - INFO - Val   Log_return: -0.0046\n",
      "2025-12-08 16:40:33,054 - INFO - Val   Mean_return: 0.0052\n",
      "2025-12-08 16:40:33,054 - INFO - \n",
      "2025-12-08 16:40:33,054 - INFO - Epoch 4/20\n",
      "2025-12-08 16:40:34,010 - INFO - Train Loss: -0.0098        \n",
      "2025-12-08 16:40:34,011 - INFO - Train Log_return: -0.0168\n",
      "2025-12-08 16:40:34,011 - INFO - Train Mean_return: 0.0192\n",
      "2025-12-08 16:40:34,011 - INFO - Val   Loss: -0.0023\n",
      "2025-12-08 16:40:34,012 - INFO - Val   Log_return: -0.0039\n",
      "2025-12-08 16:40:34,012 - INFO - Val   Mean_return: 0.0045\n",
      "2025-12-08 16:40:34,012 - INFO - \n",
      "2025-12-08 16:40:34,013 - INFO - Epoch 5/20\n",
      "2025-12-08 16:40:34,984 - INFO - Train Loss: -0.0097        \n",
      "2025-12-08 16:40:34,985 - INFO - Train Log_return: -0.0165\n",
      "2025-12-08 16:40:34,985 - INFO - Train Mean_return: 0.0189\n",
      "2025-12-08 16:40:34,985 - INFO - Val   Loss: 0.0011\n",
      "2025-12-08 16:40:34,986 - INFO - Val   Log_return: -0.0017\n",
      "2025-12-08 16:40:34,986 - INFO - Val   Mean_return: 0.0027\n",
      "2025-12-08 16:40:34,986 - INFO - \n",
      "2025-12-08 16:40:34,986 - INFO - Epoch 6/20\n",
      "2025-12-08 16:40:35,988 - INFO - Train Loss: -0.0097        \n",
      "2025-12-08 16:40:35,989 - INFO - Train Log_return: -0.0176\n",
      "2025-12-08 16:40:35,989 - INFO - Train Mean_return: 0.0203\n",
      "2025-12-08 16:40:35,989 - INFO - Val   Loss: -0.0017\n",
      "2025-12-08 16:40:35,990 - INFO - Val   Log_return: -0.0037\n",
      "2025-12-08 16:40:35,990 - INFO - Val   Mean_return: 0.0044\n",
      "2025-12-08 16:40:35,990 - INFO - \n",
      "2025-12-08 16:40:35,990 - INFO - Epoch 7/20\n",
      "2025-12-08 16:40:36,988 - INFO - Train Loss: -0.0097        \n",
      "2025-12-08 16:40:36,989 - INFO - Train Log_return: -0.0172\n",
      "2025-12-08 16:40:36,989 - INFO - Train Mean_return: 0.0197\n",
      "2025-12-08 16:40:36,989 - INFO - Val   Loss: -0.0009\n",
      "2025-12-08 16:40:36,989 - INFO - Val   Log_return: -0.0034\n",
      "2025-12-08 16:40:36,990 - INFO - Val   Mean_return: 0.0042\n",
      "2025-12-08 16:40:36,990 - INFO - \n",
      "2025-12-08 16:40:36,990 - INFO - Epoch 8/20\n",
      "2025-12-08 16:40:37,977 - INFO - Train Loss: -0.0114        \n",
      "2025-12-08 16:40:37,977 - INFO - Train Log_return: -0.0200\n",
      "2025-12-08 16:40:37,978 - INFO - Train Mean_return: 0.0229\n",
      "2025-12-08 16:40:37,978 - INFO - Val   Loss: -0.0007\n",
      "2025-12-08 16:40:37,978 - INFO - Val   Log_return: -0.0031\n",
      "2025-12-08 16:40:37,979 - INFO - Val   Mean_return: 0.0040\n",
      "2025-12-08 16:40:37,979 - INFO - \n",
      "2025-12-08 16:40:37,979 - INFO - Epoch 9/20\n",
      "2025-12-08 16:40:38,964 - INFO - Train Loss: -0.0095        \n",
      "2025-12-08 16:40:38,965 - INFO - Train Log_return: -0.0181\n",
      "2025-12-08 16:40:38,965 - INFO - Train Mean_return: 0.0210\n",
      "2025-12-08 16:40:38,965 - INFO - Val   Loss: -0.0023\n",
      "2025-12-08 16:40:38,966 - INFO - Val   Log_return: -0.0039\n",
      "2025-12-08 16:40:38,966 - INFO - Val   Mean_return: 0.0045\n",
      "2025-12-08 16:40:38,966 - INFO - \n",
      "2025-12-08 16:40:38,966 - INFO - Epoch 10/20\n",
      "2025-12-08 16:40:39,931 - INFO - Train Loss: -0.0108        \n",
      "2025-12-08 16:40:39,931 - INFO - Train Log_return: -0.0184\n",
      "2025-12-08 16:40:39,932 - INFO - Train Mean_return: 0.0210\n",
      "2025-12-08 16:40:39,932 - INFO - Val   Loss: -0.0001\n",
      "2025-12-08 16:40:39,932 - INFO - Val   Log_return: -0.0028\n",
      "2025-12-08 16:40:39,932 - INFO - Val   Mean_return: 0.0038\n",
      "2025-12-08 16:40:39,933 - INFO - \n",
      "2025-12-08 16:40:39,933 - INFO - Epoch 11/20\n",
      "2025-12-08 16:40:40,917 - INFO - Train Loss: -0.0101        \n",
      "2025-12-08 16:40:40,918 - INFO - Train Log_return: -0.0178\n",
      "2025-12-08 16:40:40,918 - INFO - Train Mean_return: 0.0205\n",
      "2025-12-08 16:40:40,918 - INFO - Val   Loss: -0.0013\n",
      "2025-12-08 16:40:40,919 - INFO - Val   Log_return: -0.0041\n",
      "2025-12-08 16:40:40,919 - INFO - Val   Mean_return: 0.0051\n",
      "2025-12-08 16:40:40,919 - INFO - Early stopping triggered at epoch 11\n",
      "2025-12-08 16:40:41,438 - INFO - [PolicyGradient] [VAL] Epoch 0/10 — CumulativeReturn: 0.3454, MeanReturnPercentage: 2.3390, ARR: 0.3150, AVOL: 0.0895, MDD: 3.8795, ASR: 3.5193, CR: 0.0812, DDR: 4.6686, SoR: 1.2008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PolicyGradient] [VAL] Epoch 0/10 — Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:40:41,920 - INFO - Found better val loss, updating episode_returns\n",
      "2025-12-08 16:40:41,921 - INFO - Len of episode_returns: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for 1970-01-02 00:00:00-05:00 to 2015-01-01 00:00:00+00:00 with train set last date 2013-01-01 00:00:00+00:00 and val set last date 2014-01-01 00:00:00+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 16:40:43,011 - WARNING - No data found for ek_us_d.csv in root folder\n",
      "2025-12-08 16:40:45,759 - INFO - retrieved 28 assets\n",
      "2025-12-08 16:40:45,760 - INFO - Using monolithic slices with -60 timestamps\n",
      "2025-12-08 16:40:46,683 - INFO - Found 10848 train slices, 333 val slices, 336 test slices\n",
      "2025-12-08 16:40:46,684 - INFO - Trained per-asset targets\n"
     ]
    }
   ],
   "source": [
    "realized_returns = []\n",
    "actions = []\n",
    "for i in range(len(start_end_last_train_dates)):\n",
    "    best_model = None\n",
    "    best_loss = 100.\n",
    "    episode_returns = None\n",
    "    for j in range(1): \n",
    "        cur_actions, cur_returns, cur_model, cur_val_loss = evaluate_signal_predictor(\n",
    "            start_end_last_train_dates[i]['symbols'],\n",
    "            start_end_last_train_dates[i]['end'], \n",
    "            start_end_last_train_dates[i]['last_train_date'], \n",
    "            start_end_last_train_dates[i]['last_val_date'], \n",
    "            best_model)\n",
    "        if cur_val_loss < best_loss: \n",
    "            logging.info('Found better val loss, updating episode_returns')\n",
    "            best_loss = cur_val_loss\n",
    "            episode_returns = cur_returns\n",
    "            episode_actions = cur_actions\n",
    "    logging.info(f'Len of episode_returns: {len(episode_returns)}')\n",
    "    realized_returns.extend(episode_returns)\n",
    "    actions.extend(episode_actions)\n",
    "    \n",
    "    # for j in range(1): \n",
    "    #     cur_rezlized_returns, model = evaluate_signal_predictor(\n",
    "    #         start_end_last_train_dates[i]['start'], \n",
    "    #         start_end_last_train_dates[i]['last_val_date'], \n",
    "    #         start_end_last_train_dates[i]['last_train_date'])\n",
    "    #     if np.mean(cur_rezlized_returns) > best_mean_return:\n",
    "    #         best_mean_return = np.mean(cur_rezlized_returns)\n",
    "    #         best_model = model\n",
    "\n",
    "    # realized_returns.extend(\n",
    "    #     evaluate_signal_predictor(\n",
    "    #         start_end_last_train_dates[i]['end'], \n",
    "    #         start_end_last_train_dates[i]['last_train_date'], \n",
    "    #         start_end_last_train_dates[i]['last_val_date'], \n",
    "    #         best_model)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5bf4cb-8a52-4b49-9201-eabc5e52b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(realized_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b4623a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cumulative_wealth(\n",
    "    returns_dict={\n",
    "        'Signal Predictor': realized_returns,\n",
    "    }, \n",
    "    start_time=config.data_config.val_set_last_date, \n",
    "    end_time=config.data_config.end,\n",
    "    compare_to_baseline=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1db313-fc7c-4fd8-9939-304e74557942",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricsCalculator(\n",
    "    metrics=DEFAULT_METRICS\n",
    ")(realized_returns)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385cbc66-8bf9-430b-bf93-23914f3876a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_position_heatmap(actions[-20:], asset_names=sorted(list(Constants.Data.DJIA_2000_2004[:-2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836eec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(realized_returns).to_csv('realized_returns_ours.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa93e1-bfcf-41d8-94ef-b5bc3e320978",
   "metadata": {},
   "outputs": [],
   "source": [
    "[sum(action) for action in actions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ddca8a-af53-4776-b33e-cbf0e665b09b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0766ac-c223-41b8-b4b4-90e15727392d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
