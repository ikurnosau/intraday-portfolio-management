{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3a6dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Format for the log messages\n",
    "    handlers=[\n",
    "        logging.StreamHandler()  # Log to the console\n",
    "    ]\n",
    ")\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from data.raw.retrievers.alpaca_markets_retriever import AlpacaMarketsRetriever\n",
    "from config.constants import *\n",
    "from data.processed.dataset_creation import DatasetCreator\n",
    "from data.processed.indicators import *\n",
    "from data.processed.targets import Balanced3ClassClassification\n",
    "from data.processed.normalization import ZScoreOverWindowNormalizer, ZScoreNormalizer, MinMaxNormalizer\n",
    "from data.processed.missing_values_handling import DummyMissingValuesHandler\n",
    "from data.processed.dataset_pytorch import DatasetPytorch\n",
    "from modeling.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b97dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.experiments.cur_experiment import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "755a729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = AlpacaMarketsRetriever()\n",
    "\n",
    "retrieval_result = retriever.bars(\n",
    "    symbol_or_symbols=config.data_config.symbol_or_symbols, \n",
    "    start=config.data_config.start, \n",
    "    end=config.data_config.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18d48d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-15 19:07:45,930 - INFO - Processing AAPL...\n",
      "2025-06-15 19:07:45,932 - INFO - Missing values are handled!\n",
      "2025-06-15 19:07:48,591 - INFO - Features calculated!\n",
      "2025-06-15 19:07:48,664 - INFO - Features normalized!\n",
      "2025-06-15 19:07:48,720 - INFO - Target calculated!\n",
      "2025-06-15 19:07:48,749 - INFO - Dropped 43 rows with NaN values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((63001, 37), (63001,), (17052, 37), (17052,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_creator = DatasetCreator(\n",
    "    features=config.data_config.features,\n",
    "    target=config.data_config.target,\n",
    "    normalizer=config.data_config.normalizer,\n",
    "    missing_values_handler=config.data_config.missing_values_handler,\n",
    "    train_set_last_date=config.data_config.train_set_last_date, \n",
    "    in_seq_len=config.data_config.in_seq_len,\n",
    "    flatten_sequence=config.data_config.flatten_sequence\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, y_test = dataset_creator.create_dataset_numpy(retrieval_result)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b98a4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DatasetPytorch(X_train, y_train).as_dataloader(\n",
    "    batch_size=config.data_config.batch_size,\n",
    "    shuffle=config.data_config.shuffle\n",
    ")\n",
    "test_loader = DatasetPytorch(X_test, y_test).as_dataloader(\n",
    "    batch_size=config.data_config.batch_size,\n",
    "    shuffle=config.data_config.shuffle\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c4b5aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=37, out_features=128, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=64, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = config.model_config.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a3858fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=test_loader,\n",
    "    loss_fn=config.train_config.loss_fn,\n",
    "    optimizer=config.train_config.optimizer,\n",
    "    scheduler=config.train_config.scheduler,\n",
    "    num_epochs=config.train_config.num_epochs,\n",
    "    device=config.train_config.device,\n",
    "    metrics=config.train_config.metrics,\n",
    "    save_path=config.train_config.save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f01c52e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-15 19:07:50,752 - INFO - Epoch 1/10\n",
      "2025-06-15 19:08:05,354 - INFO - Train Loss: 1.0695           \n",
      "2025-06-15 19:08:05,354 - INFO - Train Accuracy: 0.4058\n",
      "2025-06-15 19:08:05,355 - INFO - Val   Loss: 1.0706\n",
      "2025-06-15 19:08:05,356 - INFO - Val   Accuracy: 0.4019\n",
      "2025-06-15 19:08:05,357 - INFO - \n",
      "2025-06-15 19:08:05,358 - INFO - Epoch 2/10\n",
      "2025-06-15 19:08:19,780 - INFO - Train Loss: 1.0566           \n",
      "2025-06-15 19:08:19,781 - INFO - Train Accuracy: 0.4224\n",
      "2025-06-15 19:08:19,782 - INFO - Val   Loss: 1.0629\n",
      "2025-06-15 19:08:19,783 - INFO - Val   Accuracy: 0.4134\n",
      "2025-06-15 19:08:19,784 - INFO - \n",
      "2025-06-15 19:08:19,786 - INFO - Epoch 3/10\n",
      "2025-06-15 19:08:33,860 - INFO - Train Loss: 1.0528           \n",
      "2025-06-15 19:08:33,861 - INFO - Train Accuracy: 0.4262\n",
      "2025-06-15 19:08:33,863 - INFO - Val   Loss: 1.0621\n",
      "2025-06-15 19:08:33,864 - INFO - Val   Accuracy: 0.4109\n",
      "2025-06-15 19:08:33,865 - INFO - \n",
      "2025-06-15 19:08:33,867 - INFO - Epoch 4/10\n",
      "2025-06-15 19:08:46,935 - INFO - Train Loss: 1.0514           \n",
      "2025-06-15 19:08:46,937 - INFO - Train Accuracy: 0.4260\n",
      "2025-06-15 19:08:46,938 - INFO - Val   Loss: 1.0614\n",
      "2025-06-15 19:08:46,940 - INFO - Val   Accuracy: 0.4124\n",
      "2025-06-15 19:08:46,941 - INFO - \n",
      "2025-06-15 19:08:46,941 - INFO - Epoch 5/10\n",
      "2025-06-15 19:09:00,527 - INFO - Train Loss: 1.0507           \n",
      "2025-06-15 19:09:00,527 - INFO - Train Accuracy: 0.4266\n",
      "2025-06-15 19:09:00,528 - INFO - Val   Loss: 1.0610\n",
      "2025-06-15 19:09:00,528 - INFO - Val   Accuracy: 0.4138\n",
      "2025-06-15 19:09:00,530 - INFO - \n",
      "2025-06-15 19:09:00,530 - INFO - Epoch 6/10\n",
      "2025-06-15 19:09:14,217 - INFO - Train Loss: 1.0501           \n",
      "2025-06-15 19:09:14,218 - INFO - Train Accuracy: 0.4277\n",
      "2025-06-15 19:09:14,218 - INFO - Val   Loss: 1.0604\n",
      "2025-06-15 19:09:14,220 - INFO - Val   Accuracy: 0.4149\n",
      "2025-06-15 19:09:14,220 - INFO - \n",
      "2025-06-15 19:09:14,221 - INFO - Epoch 7/10\n",
      "2025-06-15 19:09:27,663 - INFO - Train Loss: 1.0464           \n",
      "2025-06-15 19:09:27,664 - INFO - Train Accuracy: 0.4308\n",
      "2025-06-15 19:09:27,665 - INFO - Val   Loss: 1.0600\n",
      "2025-06-15 19:09:27,665 - INFO - Val   Accuracy: 0.4154\n",
      "2025-06-15 19:09:27,666 - INFO - \n",
      "2025-06-15 19:09:27,666 - INFO - Epoch 8/10\n",
      "2025-06-15 19:09:40,749 - INFO - Train Loss: 1.0460           \n",
      "2025-06-15 19:09:40,750 - INFO - Train Accuracy: 0.4319\n",
      "2025-06-15 19:09:40,751 - INFO - Val   Loss: 1.0596\n",
      "2025-06-15 19:09:40,752 - INFO - Val   Accuracy: 0.4160\n",
      "2025-06-15 19:09:40,754 - INFO - \n",
      "2025-06-15 19:09:40,755 - INFO - Epoch 9/10\n",
      "2025-06-15 19:09:54,243 - INFO - Train Loss: 1.0458           \n",
      "2025-06-15 19:09:54,245 - INFO - Train Accuracy: 0.4320\n",
      "2025-06-15 19:09:54,245 - INFO - Val   Loss: 1.0594\n",
      "2025-06-15 19:09:54,246 - INFO - Val   Accuracy: 0.4159\n",
      "2025-06-15 19:09:54,247 - INFO - \n",
      "2025-06-15 19:09:54,247 - INFO - Epoch 10/10\n",
      "2025-06-15 19:10:08,389 - INFO - Train Loss: 1.0457           \n",
      "2025-06-15 19:10:08,390 - INFO - Train Accuracy: 0.4321\n",
      "2025-06-15 19:10:08,391 - INFO - Val   Loss: 1.0592\n",
      "2025-06-15 19:10:08,393 - INFO - Val   Accuracy: 0.4158\n",
      "2025-06-15 19:10:08,394 - INFO - \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(MLPClassifier(\n",
       "   (model): Sequential(\n",
       "     (0): Linear(in_features=37, out_features=128, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "     (3): ReLU(inplace=True)\n",
       "     (4): Linear(in_features=64, out_features=3, bias=True)\n",
       "   )\n",
       " ),\n",
       " {'train_loss': [1.069474842446658,\n",
       "   1.056639622104174,\n",
       "   1.0527823213818959,\n",
       "   1.0514044884257416,\n",
       "   1.0507064070902603,\n",
       "   1.0501154630907057,\n",
       "   1.0463590823253923,\n",
       "   1.0459872663111902,\n",
       "   1.0458445272026722,\n",
       "   1.045736674156935],\n",
       "  'val_loss': [1.0705604401135758,\n",
       "   1.0629158789400313,\n",
       "   1.062076203930445,\n",
       "   1.061362023425147,\n",
       "   1.0610294354342162,\n",
       "   1.0604307389840848,\n",
       "   1.0600359605356184,\n",
       "   1.0596175279894644,\n",
       "   1.0593708239174247,\n",
       "   1.0592253614098226],\n",
       "  'train_accuracy': [0.40577069578466224,\n",
       "   0.42239906043676995,\n",
       "   0.42618080243778567,\n",
       "   0.4259630523108177,\n",
       "   0.4265820213306247,\n",
       "   0.4276771203656679,\n",
       "   0.4307719654647029,\n",
       "   0.43186262061960384,\n",
       "   0.4319895886236668,\n",
       "   0.43214829862874554],\n",
       "  'val_accuracy': [0.40186947199142325,\n",
       "   0.41336940498525865,\n",
       "   0.4109069284374163,\n",
       "   0.41237268828732243,\n",
       "   0.41383844813722864,\n",
       "   0.4148937952291611,\n",
       "   0.4154214687751273,\n",
       "   0.4160077727150898,\n",
       "   0.41594914232109353,\n",
       "   0.4158318815331011]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed829636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca16d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9435\n",
      "[LightGBM] [Info] Number of data points in the train set: 63001, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score -1.089668\n",
      "[LightGBM] [Info] Start training from score -1.115096\n",
      "[LightGBM] [Info] Start training from score -1.091274\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ikurnosau\\anaconda3\\envs\\mldl\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.4201853155055125, bestparams: None\n"
     ]
    }
   ],
   "source": [
    "import itertools \n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.datasets import make_classification\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "def evaluate_model_accuracy(model, param_grid=None):\n",
    "    def evaluate_cur_model(cur_model, best_accuracy): \n",
    "        cur_model = cur_model.fit(X_train, y_train)\n",
    "        test_preds = cur_model.predict(X_test)\n",
    "        best_accuracy = accuracy_score(y_test, test_preds)\n",
    "\n",
    "        return best_accuracy\n",
    "\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_params = None \n",
    "    if param_grid:\n",
    "        keys, values = zip(*param_grid.items())\n",
    "        param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "        for param_compbination in param_combinations: \n",
    "            cur_model = clone(model).set_params(**param_compbination)\n",
    "            cur_accuracy = evaluate_cur_model(cur_model, best_accuracy)\n",
    "            if cur_accuracy > best_accuracy: \n",
    "                best_accuracy = cur_accuracy\n",
    "                best_params = param_compbination\n",
    "    else: \n",
    "        cur_accuracy = evaluate_cur_model(model, best_accuracy)\n",
    "        if cur_accuracy > best_accuracy: \n",
    "            best_accuracy = cur_accuracy\n",
    "            best_params = None\n",
    "\n",
    "    print(f'Best accuracy: {best_accuracy}, bestparams: {best_params}')\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=1000, \n",
    "    learning_rate=0.001,\n",
    "    max_depth=5,\n",
    "    num_leaves=31, \n",
    "    objective='multiclass', \n",
    "    num_class=3\n",
    "    )\n",
    "evaluate_model_accuracy(lgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4362df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6bf2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
